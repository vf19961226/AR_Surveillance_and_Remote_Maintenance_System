# 2022/04/27 單機實現AR演算法（2）
###### tags: `論文實做紀錄` `AR演算法`
## 實作環境
參考2022/04/26 單機實現AR演算法（1）的[實作環境](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。

## 實作紀錄
### 相機校正
使用ArUco進行校正，以取得相機之內部參數與外部參數，其中內部參數（相機矩陣）與畸變係數將用於後續之相機姿態估計。相機校正步驟如下所述。

1. **創建ArUco校正板**
使用`cv2.aruco.CharucoBoard_create()`創建ArUco校正板，ArUco校正板如下圖所示。校正板中的ArUco標籤一樣由`cv2.aruco.Dictionary_get()`創建的標籤字典中挑選，在校正板生成後將其儲存到本機中，以利後續校正時使用。創建創建ArUco校正板程式如下所示。程式中的相關參數意義如下表所示。

![ArUco校正板](https://i.imgur.com/hkS2Wvx.png)

```python=
#創建ArUco標籤字典
dictionary = cv2.aruco.Dictionary_get(10)
#創建校正板
board = cv2.aruco.CharucoBoard_create(squaresX, squaresY, squareLength, markerLength, dictionary)
#繪製校正板
img = board.draw((Width, High))
#儲存繪製完成後的校正板
cv2.imwrite("board.png", img)
```

|參數名稱|參數意義|
|:---:|:---
|squaresX|X方向的方格數
|squaresY|Y方向的方格數
|squareLength|ArUco校正板邊長
|markerLength|ArUco標籤邊長
|dictionary|校正板中標籤所使用的ArUco標籤字典
|Width|校正板畫板寬度
|High|校正板畫板高度

2. **開啟相機擷取影像**
如何開啟相機這邊就不贅述了，可參考2022/04/26 單機實現AR演算法（1）的[ArUco標籤辨識](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#ArUco%E6%A8%99%E7%B1%A4%E8%BE%A8%E8%AD%98)，其中第2步為開啟相機。

3. **ArUco校正板標籤辨識**
這裡的ArUco標籤辨識與2022/04/26 單機實現AR演算法（1）的[ArUco標籤辨識](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#ArUco%E6%A8%99%E7%B1%A4%E8%BE%A8%E8%AD%98)有些許不同，這裡加入了`cv2.cornerSubPix()`亞像素角點檢測方法，用以提升ArUco標籤辨識之精準度，以及`cv2.aruco.interpolateCornersCharuco()`區分是否為校正板上標籤，並將其以標籤為單位區分。程式如下所示。程式中的相關參數意義如下表所示。

```python=
corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, dictionary)
if len(corners)>0:
    for corner in corners:
        cv2.cornerSubPix(gray, corner, winSize, zeroZone, criteria)
    res2 = cv2.aruco.interpolateCornersCharuco(corners,ids,gray,board)
```

|參數名稱|參數意義|
|:---:|:---
|corners|辨識出正確標籤的頂點位置
|ids|辨識出正確標籤於ArUco標籤字典中的編號
|rejected_corners|辨識出不正確標籤的頂點位置
|gray|欲辨識標籤的灰階圖片
|dictionary|ArUco標籤字典
|winSize|計算亞像素角點時考慮的區域的大小
|zeroZone|作用類似於winSize，但是總是具有較小的範圍，通常忽略
|criteria|用於表示計算亞畫素時停止迭代的標準
|res2|輸出標籤位置、標籤id、標籤的數量等數據集合

4. **相機影像校正**
將前述第3步獲得的ArUco校正板標籤位置、標籤id、標籤數量以及相機影像大小等資訊，使用`cv2.aruco.calibrateCameraCharucoExtended()`函式進行影像校正，以獲得像機之內部參數與外部參數。程式如下所示。程式中的相關參數意義如下表所示。

```python=
(ret, camera_matrix, distortion_coefficients0,
     rotation_vectors, translation_vectors,
     stdDeviationsIntrinsics, stdDeviationsExtrinsics,
     perViewErrors) = cv2.aruco.calibrateCameraCharucoExtended(
                      charucoCorners,
                      charucoIds,
                      board,
                      imageSize,
                      cameraMatrix,
                      distCoeffs,
                      flags,
                      criteria)
```

|參數名稱|參數意義|
|:---:|:---
|ret|
|camera_matrix|相機矩陣（內部參數）
|distortion_coefficients|失真係數
|rotation_vectors|旋轉矩陣
|translation_vectors|平移矩陣
|stdDeviationsIntrinsics|內在參數估計的標準偏差的輸出向量
|stdDeviationsExtrinsics|外部參數估計的標準偏差的輸出向量
|perViewErrors|每個模式視圖估計的RMS重投影誤差的輸出向量
|charucoCorners|辨識出正確標籤的頂點位置
|charucoIds|辨識出正確標籤於ArUco標籤字典中的編號
|board|ArUco校正板布局
|imageSize|輸入校正相機影像大小
|cameraMatrix|預設相機矩陣
|distCoeffs|預設失真係數
|flags|可能為零或以下值組合的不同標誌，[組合參考](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gga11738a219783c6dc7fdeb093a4a87c0fa6eedf3c8312d4b29edfe0a434722e2ef)
|criteria|迭代優化算法的終止標準

5. **儲存相機參數**
使用`np.savez()`函式儲存相機參數與失真係數於.npz檔案中，以方便後續相機姿態估計使用。

### 擴增實境投影顯示
使用前述相機影像校正獲得的相機參數進行相機姿態估計後，獲得相機之平移與旋轉矩陣（相機相對於標籤的位置與旋轉角度），並以此為基礎將影像合成於影像中顯示，顯示結果如下圖所示。其詳細實作步驟如下所述。

![AR投影顯示](https://i.imgur.com/x7CliJj.png)

1. **載入相機參數**
使用`np.load()`載入前述相機校正獲得的相機參數，並讀取儲存於其中的相機內部矩陣與畸變係數。

2. **開啟相機進行標籤檢測**
此步驟與2022/04/26 單機實現AR演算法（1）的[ArUco標籤辨識](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#ArUco%E6%A8%99%E7%B1%A4%E8%BE%A8%E8%AD%98)相同，故不再贅述。

3. **相機姿態估計**
使用`cv2.aruco.estimatePoseSingleMarkers()`對相機姿態進行估計，並獲得旋轉與平移矩陣（相機相對於標籤的位置與旋轉角度），且可以利用`cv2.aruco.drawAxis()`繪製以ArUco標籤中心為原點之三維座標軸，如下圖所示。程式如下所示。程式中的相關參數意義如下表所示。

![相機姿態估計(顯示三維座標)](https://i.imgur.com/U3OSH0P.png)

```python=
rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs)
for rvec, tvec in zip(rvecs, tvecs):
    cv2.aruco.drawAxis(frame, cameraMatrix, distCoeffs, rvec, tvec, axisLength)
```

|參數名稱|參數意義|
|:---:|:---
|rvecs|相機旋轉矩陣
|tvecs|相機平移矩陣
|corners|ArUco標籤之角點座標
|markerLength|標籤長度
|cameraMatrix|相機矩陣（內部參數）
|distCoeffs|相機畸變參數
|frame|輸入影像
|axisLength|座標軸長度

4. **AR影像合成**
需先定義欲投影物件外觀形狀座標後，利用`cv2.projectPoints()`將投影物件外觀座標投影至ArUco標籤上，並利用透視變換方法將欲顯示的影像顯示於ArUco標籤上。程式如下所示。程式中的相關參數意義如下表所示。[參考1](https://hackmd.io/yT3kcorQQ-aOUcm4TvPo6g?view#%E3%80%90OpenCV3%E3%80%91%E9%80%8F%E8%A7%86%E5%8F%98%E6%8D%A2)、[參考2](https://hackmd.io/yT3kcorQQ-aOUcm4TvPo6g?view#%E3%80%90%E6%B2%92%E9%8C%A2ps%E6%88%91%E7%94%A8OpenCV%E3%80%91Day-22---%E7%B6%9C%E5%90%88%E9%81%8B%E7%94%A81%EF%BC%8C%E7%94%A8-OpenCV-%E4%BE%86P%E5%9C%96%E5%9B%89-%E4%BE%86%E9%81%8B%E7%94%A8%E5%90%84%E7%A8%AE%E4%B9%8B%E5%89%8D%E5%AD%B8%E7%BF%92%E7%9A%84%E5%90%84%E7%A8%AE%E6%9D%B1%E8%A5%BF%E5%90%A7-merge-two-images)。

```python=
projected_desired_points, jac = cv2.projectPoints(desired_points, rvec, tvec, cameraMatrix, distCoeffs)

pts = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],
[0, overlay_image.shape[0]]])

cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)

M = cv2.getPerspectiveTransform(pts, projected_desired_points)
dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))

dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)
ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)
image_masked = cv2.bitwise_and(image, image, mask=mask)

result = cv2.add(dst_image, image_masked)
```

|參數名稱|參數意義|
|:---:|:---
|projected_desired_points|欲投影物件之外觀形狀座標投影於ArUco標籤之座標
|jac|
|desired_points|預設欲投影物件之外觀形狀座標
|rvec|相機旋轉矩陣
|tvec|相機平移矩陣
|cameraMatrix|相機矩陣（內部參數）
|distCoeffs|相機畸變參數
|pts|欲投影物件外觀座標
|overlay_image|欲投影物件（2D影像）
|M|轉換矩陣
|image|欲投影之基底影像
|mask|影像遮罩

## 程式碼整理
### ArUco影像校正
```python=
import cv2
import numpy as np

# 創建ArUco校正板
def create_board(dictionary):
    board = cv2.aruco.CharucoBoard_create(3, 3, .025, .0125, dictionary)
    img = board.draw((200 * 3, 200 * 3))
    cv2.imwrite("board.png", img)
    
    return board

# 標籤辨識（相機校正）
def read_chessboards(img, dictionary, board):
    # SUB PIXEL CORNER DETECTION CRITERION
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.00001)
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, dictionary)
    
    if len(corners)>0:
        # SUB PIXEL DETECTION
        for corner in corners:
            cv2.cornerSubPix(gray, corner,
                             winSize = (3,3),
                             zeroZone = (-1,-1),
                             criteria = criteria)
        res2 = cv2.aruco.interpolateCornersCharuco(corners,ids,gray,board)
    
        return res2, gray.shape
    
#相機校正
def calibrate_camera(allCorners,allIds,board, imsize):
    """
    Calibrates the camera using the dected corners.
    """
    print("CAMERA CALIBRATION")

    cameraMatrixInit = np.array([[ 1000.,    0., imsize[0]/2.],
                                 [    0., 1000., imsize[1]/2.],
                                 [    0.,    0.,           1.]])

    distCoeffsInit = np.zeros((5,1))
    flags = (cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_RATIONAL_MODEL + cv2.CALIB_FIX_ASPECT_RATIO)
    #flags = (cv2.CALIB_RATIONAL_MODEL)
    (ret, camera_matrix, distortion_coefficients0,
     rotation_vectors, translation_vectors,
     stdDeviationsIntrinsics, stdDeviationsExtrinsics,
     perViewErrors) = cv2.aruco.calibrateCameraCharucoExtended(
                      charucoCorners=allCorners,
                      charucoIds=allIds,
                      board=board,
                      imageSize=imsize,
                      cameraMatrix=cameraMatrixInit,
                      distCoeffs=distCoeffsInit,
                      flags=flags,
                      criteria=(cv2.TERM_CRITERIA_EPS & cv2.TERM_CRITERIA_COUNT, 10000, 1e-9))

    return ret, camera_matrix, distortion_coefficients0, rotation_vectors, translation_vectors

dictionary = cv2.aruco.Dictionary_get(10)
board = create_board(dictionary)

# 創建視頻捕獲對象
capture = cv2.VideoCapture(0)
capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

allCorners = []
allIds = []
decimator = 0
while (decimator <= 20): # 擷取20張相片進行相機校正
    # 捕獲視頻幀
    ret, frame = capture.read()
    cv2.imshow('frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        res2, imsize = read_chessboards(frame, dictionary, board)
    
        if res2[1] is not None and res2[2] is not None and len(res2[1])>3 and decimator%1==0:
            allCorners.append(res2[1])
            allIds.append(res2[2])
        decimator+=1
# 銷毀窗口
capture.release()
cv2.destroyAllWindows()

ret, mtx, dist, rvecs, tvecs = calibrate_camera(allCorners,allIds,board, imsize)

if ret <= 3:
    np.savez('Camera_parameter.npz', mtx = mtx, dist = dist)
    print('Parameter is saved.')
else:
    print('Please calibrate camera again.')
```

### 擴增實境投影顯示
```python=
import cv2
import numpy as np

def draw_augmented_overlay(pts_1, overlay_image, image):
    # 定義要繪制的疊加圖像的正方形
    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],
    [0, overlay_image.shape[0]]])
    # 繪制邊框以查看圖像邊框
    cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)
    # 創建轉換矩陣
    M = cv2.getPerspectiveTransform(pts_2, pts_1)
    # 使用變換矩陣M變換融合圖像
    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))
    # 創建掩碼
    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)
    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)
    # 使用計算出的掩碼計算按比特與
    image_masked = cv2.bitwise_and(image, image, mask=mask)
    # 兩個圖像進行加和創建結果圖像
    result = cv2.add(dst_image, image_masked)
    return result

parameter = np.load('Camera_parameter.npz')
cameraMatrix = parameter['mtx']
distCoeffs = parameter['dist']

dictionary = cv2.aruco.Dictionary_get(10)
parameters = cv2.aruco.DetectorParameters_create()

OVERLAY_SIZE_PER = 1

show_img = cv2.imread('Jewel_Changi.jpg')

# 創建視頻捕獲對象
capture = cv2.VideoCapture(0)
capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
while True:
    # 捕獲視頻幀
    ret, frame = capture.read()
    # 轉化為灰度圖像
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    # 檢測圖像中標記
    corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray_frame, dictionary, parameters=parameters)
    
    # 繪制檢測標記
    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))
    
    if ids is not None:
        # rvecs, tvecs分別是角點中每個標記的旋轉和平移向量
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)
        
    # rvecs, tvecs分別是角點中每個標記的旋轉和平移向量
    for rvec, tvec in zip(rvecs, tvecs):
        desired_points = np.float32([[-1 / 2, 1 / 2, 0], [1 / 2, 1 / 2, 0], [1 / 2, -1 / 2, 0], [-1 / 2, -1 / 2, 0]]) * OVERLAY_SIZE_PER
        # 投影點
        projected_desired_points, jac = cv2.projectPoints(desired_points, rvec, tvec, cameraMatrix, distCoeffs)
        # 繪制投影點
        frame = draw_augmented_overlay(projected_desired_points, show_img, frame)
        # 繪製系統軸
        #cv2.aruco.drawAxis(frame, cameraMatrix, distCoeffs, rvec, tvec, 1)
    
    # 展示結果
    cv2.imshow('frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        cv2.imwrite("AR_img.png", frame)
        break
# 銷毀窗口
capture.release()
cv2.destroyAllWindows()
```

## Reference
### [OpenCV-Python實戰（12）——一文詳解AR增强現實](https://pythonmana.com/2021/10/20211024210351384d.html)
用OpenCV進行AR應用開發，以**Python**進行編程，含有二維碼生成，並用期進行影校校正與相機姿態估計

### [Camera calibration using CHARUCO](https://mecaruco2.readthedocs.io/en/latest/notebooks_rst/Aruco/sandbox/ludovic/aruco_calibration_rotation.html)
如何使用ArUco進行影像校正

### [cv::cornerSubPix()亞畫素角點檢測](https://www.796t.com/content/1544079906.html)

### [cv.interpolateCornersCharuco](https://amroamroamro.github.io/mexopencv/matlab/cv.interpolateCornersCharuco.html)

### [Camera Calibration and 3D Reconstruction](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html)

### [【OpenCV3】透视变换](https://blog.csdn.net/guduruyu/article/details/72518340)
將影像中非平面物件轉換為平面

### [【沒錢ps,我用OpenCV!】Day 22 - 綜合運用1，用 OpenCV 來P圖囉! 來運用各種之前學習的各種東西吧! merge two images](https://ithelp.ithome.com.tw/articles/10248721)
將圖像與另一個圖像合成在一起