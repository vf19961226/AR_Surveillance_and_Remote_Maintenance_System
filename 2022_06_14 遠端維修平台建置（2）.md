# 2022/06/14 遠端維修平台建置（2）
###### tags: `論文實做紀錄` `遠端平台` `霧節點` `AR使用者介面` 
## 實作環境
1. **遠端平台**
遠端平台實作環境可參考[2022/06/10 遠端維修平台建置（1）的實作環境](https://hackmd.io/YBJrrhSrSLWTMjuhqslOzg?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。

2. **霧節點**
霧節點伺服器配置可參考[2022/04/26 單機實現AR演算法（1）的實作環境](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。

3. **AR設備**
AR設備環境基本上與[2022/05/19 CNC感測資料擷取與可視化（2）的實作環境](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q?view#AR%E8%A8%AD%E5%82%99)相同，唯.NET版本更改為4.7.2，並另外透過NuGet安裝了NAudio套件，版本為2.1.0。

## 實作紀錄
本次實作將遠端平台加入語音通話功能，並於霧節點中建置與遠端平台連線用的Socket Server（語音通話與AR影像串流），
最終測試遠端平台與AR設備透過霧節點進行連線是否可行。

### 遠端平台
為減少語音通話功能的開發時間，在遠端平台中的語音通話功能將使用與AR設備相同架構（.NET 4.7.2）進行開發，平台在使用上以呼叫外部執行檔的方式進行，如下圖所示。以下將分述Unity呼叫外部執行檔的程式部分，以及語音通話功能視窗程式。

![語音通話功能](https://i.imgur.com/bGHC3kw.jpg)

#### Unity呼叫外部執行檔
Unity在呼叫外部執行檔時，會建議另外使用執行續運行，否則原本Unity的程式會直接卡住，故在腳本中將執行外部執行檔的程式使用一個函式包起來，並將其輸入新創進的執行緒中執行，程式如下所示。最後將該腳本綁定至按鈕上，就可以呼叫外部執行檔了。

```csharp=
public string Exe_path; //執行檔的路徑

public void help_btn()
{
    //開啟新的執行緒，執行thread_help函式
    Thread help = new Thread(new ThreadStart(thread_help));
    help.Start();
}

private void thread_help()
{
    Process p = new Process(); //新增執行外部執行檔的物件
    p.StartInfo.FileName = Exe_path; //輸入外部執行檔路徑
    p.Start(); //執行外部執行檔
}
```

#### 語音通話功能視窗
語音通話功能視窗主要可分為音訊擷取、撥放以及Socket Client等三個部分，本次實作中使用NAudio套件進行音訊擷取與撥放，音訊擷取頻率為16KHz，解析度為16bit，音訊為單聲道。另外設置一個收到音訊時的觸發事件，將透過該事件取出音訊`e.Buffer`，透過Socket傳送至霧節點進行資料交換。

```csharp=
public void StartRec()
{
    try
    {
        waveSource = new WaveIn();//保證電腦有麥克接入否則報錯。
        waveSource.WaveFormat = new WaveFormat(16000, 16, 1); // 16KHz，16bit,單聲道的錄音格式

        waveSource.DataAvailable += new EventHandler<WaveInEventArgs>(waveSource_DataAvailable); //收到聲音時所觸發的事件

        waveSource.StartRecording(); //開始收音
    }
    catch (Exception e)
    {
        throw new Exception(e.Message);
    }
}

private void waveSource_DataAvailable(object sender, WaveInEventArgs e)
{
    clientSocket.Send(e.Buffer);
}
```

將透過Socket回傳的音訊資料透過`MemoryStream`讀取btye格式的音訊資料，接著將其進行解碼（頻率為16KHz、解析度為16bit、音訊為單聲道），最後使用`WaveOut`進行撥放。另外因為`Socket.Receive()`會阻塞程式，故將此功能使用`BackgroundWorker`於背景執行緒中執行，以防止主程式阻塞。程式如下所示。

```csharp=
private void play_voice_DoWork(object sender, DoWorkEventArgs e) //BackgroundWorker的DoWork
{
    WaveOut waveOut = new WaveOut();
    while (true)
    {
        byte[] date = new byte[3200];
        int count = clientSocket.Receive(date);

        MemoryStream ms = new MemoryStream(date);
        IWaveProvider reader = new RawSourceWaveStream(ms, new WaveFormat(16000, 16, 1));
        waveOut.Init(reader);
        waveOut.Play();
    }
}
```

在開始通話的按鈕中，有建立Socket連線、背景執行緒、開始收音等功能，
Socket連線可直接參考[2022/05/19 CNC感測資料擷取與可視化（2）的AR系統人機介面](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q#AR%E7%B3%BB%E7%B5%B1%E4%BA%BA%E6%A9%9F%E4%BB%8B%E9%9D%A2)，這裡就不再贅述。背景執行緒為前述所提到的接收遠端音訊資料，這裡使用`play_voice.RunWorkerAsync()`函式進行啟動，開始收音則為前述所定義的函式`StartRec()`。程式如下所示。

```csharp=
private void button1_Click(object sender, EventArgs e)
{
    clientSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //創建一個Socket物件
    clientSocket.Connect(new IPEndPoint(IPAddress.Parse("127.0.0.1"), 7002)); //連線到Server

    play_voice.RunWorkerAsync();
    StartRec();
    button1.Text = "Calling...";
}
```

另外撰寫了一個程式退出時的機制，斷開所有連線定釋放資源，程式如下所示。
```csharp=
private void Form1_FormClosed(object sender, FormClosedEventArgs e) //按右上角的叉叉
{
    if (waveSource != null)
    {
        waveSource.Dispose();
        waveSource = null;
    }

    play_voice.CancelAsync();
    clientSocket.Close();
}

private void button2_Click(object sender, EventArgs e) //按介面中的Cancel
{
    if (waveSource != null)
    {
        waveSource.Dispose();
        waveSource = null;
    }

    play_voice.CancelAsync();
    clientSocket.Close();
    Application.Exit(); //關閉程式
}
```
<font color=#FF0000>**注意：**</font>若要背景執行緒可以被跨執行緒關閉，須將其WorkerSupportsCancellati屬性設為True。

### 霧節點
在霧節點建立一個用於轉發音訊的Socket Server（Port為7003），主要就是將AR設備發送過來的音訊轉發給遠端平台，而遠端平台發送過來的音訊轉發給AR設備。所以這裡設置了兩個執行緒，以防止程式阻塞而無法正常傳遞音訊，並創建一函式用以交換音訊封包，在創建執行緒分別將兩個端點的Socket連線物件輸入函式中，使其在各自的執行緒中交換音訊封包。Socket Server的基本建置與使用可參考[2022/05/31 霧節點伺服器建置（1）的Socket Server](https://hackmd.io/N_mKpugmTDmJz4M_nzh3VA?view#Socket-Server)。程式如下所示。

```python=
class Socket_Server3(Process): #Surface跟遠端平台的語音通話
    def __init__(self, IP, PORT):
        super(Socket_Server3, self).__init__() #需要繼承父類別的的東東
        
        self.IP = IP
        self.PORT = PORT
        
        self.server_init()
        
    def server_init(self):
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.s.bind((self.IP, self.PORT))
        self.s.listen(5)
        
    def send_data(self, conn0, conn1, addr):
        print(addr)
        while 1:
            data = conn0.recv(3200) #接收音訊資料
            if data != None:
                conn1.send(data) #傳送音訊資料
        
    def run(self):
        print("Socket_Server3: {}".format(os.getpid()))

        conn, addr = self.s.accept()
        print('1. Connected by ' + str(addr))
        conn2, addr2 = self.s.accept()
        print('2. Connected by ' + str(addr2))
        
        thread0 = Thread(target = self.send_data, args = (conn, conn2, addr))
        thread1 = Thread(target = self.send_data, args = (conn2, conn, addr2))
        thread0.start()
        thread1.start()
```

### AR設備
AR設備上的語音通話功能設置方事與前述Unity的[語音通話功能視窗](https://hackmd.io/mbfGRJvuQZe632kesg2e0A?view#%E8%AA%9E%E9%9F%B3%E9%80%9A%E8%A9%B1%E5%8A%9F%E8%83%BD%E8%A6%96%E7%AA%97)設置方法相同，並將其整合至[2022/05/19 CNC感測資料擷取與可視化（2）](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q?view)已經時做完成的AR系統人機介面中。程式碼部分這邊就不再贅述，可直接參考以下程式碼整理的[AR設備](https://hackmd.io/mbfGRJvuQZe632kesg2e0A?view#AR%E8%A8%AD%E5%82%991)部分。

## 程式碼整理
### 遠端平台
#### Unity呼叫外部執行檔
```csharp=
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

using System.Diagnostics;
using System.Threading;

public class Help_btn : MonoBehaviour
{
    public string Exe_path;

    // Start is called before the first frame update
    void Start()
    {

    }

    // Update is called once per frame
    void Update()
    {

    }

    public void help_btn()
    {
        Thread help = new Thread(new ThreadStart(thread_help));
        help.Start();
    }

    private void thread_help()
    {
        Process p = new Process();
        p.StartInfo.FileName = Exe_path;
        p.Start();
    }
}
```

#### 語音通話功能視窗
```csharp=
using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;

using NAudio.Wave;
using System.IO;

//導入Socket
using System.Net.Sockets;
using System.Net;

namespace Voice_Chat2
{
    public partial class Form1 : Form
    {
        public WaveIn waveSource = null;

        Socket clientSocket;

        public Form1()
        {
            InitializeComponent();
        }

        public void StartRec()
        {
            try
            {
                waveSource = new WaveIn();//保證電腦有麥克接入否則報錯。
                waveSource.WaveFormat = new WaveFormat(16000, 16, 1); // 16KHz，16bit,單聲道的錄音格式

                waveSource.DataAvailable += new EventHandler<WaveInEventArgs>(waveSource_DataAvailable);

                waveSource.StartRecording();
            }
            catch (Exception e)
            {
                throw new Exception(e.Message);
            }
        }

        private void waveSource_DataAvailable(object sender, WaveInEventArgs e)
        {
            clientSocket.Send(e.Buffer);
        }

        private void button1_Click(object sender, EventArgs e)
        {
            clientSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //創建一個Socket物件
            clientSocket.Connect(new IPEndPoint(IPAddress.Parse("127.0.0.1"), 7002)); //連線到Server

            play_voice.RunWorkerAsync();
            StartRec();
            button1.Text = "Calling...";
        }

        private void play_voice_DoWork(object sender, DoWorkEventArgs e)
        {
            WaveOut waveOut = new WaveOut();
            while (true)
            {
                byte[] date = new byte[3200];
                int count = clientSocket.Receive(date);

                MemoryStream ms = new MemoryStream(date);
                IWaveProvider reader = new RawSourceWaveStream(ms, new WaveFormat(16000, 16, 1));
                waveOut.Init(reader);
                waveOut.Play();
            }
        }

        private void Form1_FormClosed(object sender, FormClosedEventArgs e)
        {
            if (waveSource != null)
            {
                waveSource.Dispose();
                waveSource = null;
            }

            play_voice.CancelAsync();
            clientSocket.Close();
        }

        private void button2_Click(object sender, EventArgs e)
        {
            if (waveSource != null)
            {
                waveSource.Dispose();
                waveSource = null;
            }

            play_voice.CancelAsync();
            clientSocket.Close();
            Application.Exit();
        }
    }
}
```

### 霧節點
```python=
import os
import io
import socket
import cv2
import numpy as np
from PIL import Image
from multiprocessing import Process
from xml.etree import ElementTree as ET
from xml.dom import minidom
from threading import Thread

import time

class Socket_Server(Process): #給平版用的
    def __init__(self, queue1, queue2, queue3, IP, PORT):
        super(Socket_Server, self).__init__() #需要繼承父類別的的東東
        
        self.queue1 = queue1
        self.queue2 = queue2
        self.queue3 = queue3
        
        self.IP = IP
        self.PORT = PORT
        
        self.server_init()
        
    def server_init(self):
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.s.bind((self.IP, self.PORT))
        self.s.listen(5)
        
    def bytes2img(self, indata):
        data = np.frombuffer(indata, dtype='uint8')
        try:
            image = Image.open(io.BytesIO(data))
            open_cv_image = np.array(image) 
            open_cv_image = open_cv_image[:, :, ::-1].copy() 
            self.open_cv_image2 = open_cv_image
        except:
            open_cv_image = self.open_cv_image2
        
        if open_cv_image is not None:
            self.queue1.put(open_cv_image)
            
    def img2bytes(self):
        img = self.queue2.get(True)
        
        img_encode = cv2.imencode('.jpg', img)[1]
        data_encode = np.array(img_encode)
        str_encode = data_encode.tobytes()
        
        return str_encode

    def run(self):
        print("Socket_Server: {}".format(os.getpid()))
        while 1:
            conn, addr = self.s.accept()
            print('Connected by ' + str(addr))
            
            while 1:
                indata = conn.recv(2000000)
                self.bytes2img(indata)            
                outdata = self.img2bytes()
                self.queue3.put(outdata)
                conn.send(outdata)
                
class Socket_Server2(Process): #給遠端平台用的
    def __init__(self, queue1, queue2, IP, PORT):
        super(Socket_Server2, self).__init__() #需要繼承父類別的的東東
        
        self.queue1 = queue1
        self.queue2 = queue2
        
        self.IP = IP
        self.PORT = PORT
        
        self.server_init()
        
    def server_init(self):
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.s.bind((self.IP, self.PORT))
        self.s.listen(5)
        
    def bytes2xml(self, indata):
        data = indata.decode("utf-8")
        
        xml = minidom.parseString(data)
        xml_pretty_str = xml.toprettyxml()
        
        data = ET.ElementTree(ET.fromstring(xml_pretty_str))
        data.write("test_python.xml")
        self.queue2.put(data)
            
    def img2bytes(self):
        img = self.queue1.get(True)
        img_encode = cv2.imencode('.jpg', img)[1]
        data_encode = np.array(img_encode)
        str_encode = data_encode.tobytes()

        return str_encode

    def run(self):
        print("Socket_Server2: {}".format(os.getpid()))
        while 1:
            conn, addr = self.s.accept()
            print('Connected by ' + str(addr))
            
            while 1:
                #indata = conn.recv(2000000) #接收Remote Platform傳來的資料
                #self.bytes2xml(indata)
                outdata = self.queue1.get(True)
                conn.send(outdata)
                
class Socket_Server3(Process): #Surface跟遠端平台的語音通話
    def __init__(self, IP, PORT):
        super(Socket_Server3, self).__init__() #需要繼承父類別的的東東
        
        self.IP = IP
        self.PORT = PORT
        
        self.server_init()

    def server_init(self):
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.s.bind((self.IP, self.PORT))
        self.s.listen(5)
        
    def send_data(self, conn0, conn1, addr):
        print(addr)
        while 1:
            data = conn0.recv(3200) #接收音訊資料
            if data != None:
                conn1.send(data) #傳送音訊資料
        
    def run(self):
        print("Socket_Server3: {}".format(os.getpid()))

        conn, addr = self.s.accept()
        print('1. Connected by ' + str(addr))
        conn2, addr2 = self.s.accept()
        print('2. Connected by ' + str(addr2))
        
        thread0 = Thread(target = self.send_data, args = (conn, conn2, addr))
        thread1 = Thread(target = self.send_data, args = (conn2, conn, addr2))
        thread0.start()
        thread1.start()
```

### AR設備
```csharp=
using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
//導入Socket
using System.Net.Sockets;
using System.Net;
//導入OpenCV
using OpenCvSharp;
//導入NAudio
using NAudio.Wave;
using System.IO;

namespace Surface_AR_Viewer
{
    public partial class AR_viewer : Form
    {
        public AR_viewer()
        {
            InitializeComponent();
        }

        Socket clientSocket;
        Socket clientSocket2;
        public WaveIn waveSource = null;
        VideoCapture cap;

        private void get_cam_img_DoWork(object sender, DoWorkEventArgs e)
        {
            Mat img = new Mat();
            while (true)
            {
                cap.Read(img);
                if (img.Empty())
                {
                    continue;
                }
                byte[] send_img = img.ImEncode();
                clientSocket.Send(send_img);
            }
        }

        private void conn2server_btn_Click(object sender, EventArgs e)
        {
            cap = new VideoCapture(0);
            cap.Open(1, VideoCaptureAPIs.DSHOW);
            cap.FrameHeight = 720;
            cap.FrameWidth = 1280;
            cap.Fps = 30;
            
            var v = OpenCvSharp.FourCC.FromString("MJPG");
            cap.Set(VideoCaptureProperties.FourCC, v.Value);
            
            clientSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //創建一個Socket物件
            clientSocket.Connect(new IPEndPoint(IPAddress.Parse("127.0.0.1"), 7000)); //連線到Server

            get_cam_img.RunWorkerAsync();
            show_img.RunWorkerAsync();
        }

        private void disconn2server_btn_Click(object sender, EventArgs e)
        {
            get_cam_img.CancelAsync();
            show_img.CancelAsync();

            clientSocket.Close();
            Application.Exit();
        }

        private void show_img_DoWork(object sender, DoWorkEventArgs e)
        {
            while (true)
            {
                byte[] date = new byte[2000000];
                int count = clientSocket.Receive(date);
                ImreadModes mode = ImreadModes.Color;
                Mat image = Cv2.ImDecode(date, mode);
                Bitmap bit_img = OpenCvSharp.Extensions.BitmapConverter.ToBitmap(image);
                pictureBox1.Image = bit_img;
            }
        }

        private bool help = false;
        private void help_btn_Click(object sender, EventArgs e)
        {
            clientSocket2 = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //創建一個Socket物件
            clientSocket2.Connect(new IPEndPoint(IPAddress.Parse("127.0.0.1"), 7002)); //連線到Server

            play_voice.RunWorkerAsync();

            if (!help)
            {
                StartRec();
                help_btn.Text = "Exit Help";
                help = true;
            }
            else if(help)
            {
                StopRec();
                help_btn.Text = "Help";
                help = false;
            }
        }

        public void StartRec()
        {
            try
            {
                waveSource = new WaveIn();//保證電腦有麥克接入否則報錯。
                waveSource.WaveFormat = new WaveFormat(16000, 16, 1); // 16KHz，16bit,單聲道的錄音格式

                waveSource.DataAvailable += new EventHandler<WaveInEventArgs>(waveSource_DataAvailable);

                waveSource.StartRecording();
            }
            catch (Exception e)
            {
                throw new Exception(e.Message);
            }
        }

        public void StopRec()
        {
            if (waveSource != null)
            {
                waveSource.Dispose();
                waveSource = null;
            }

            play_voice.CancelAsync();
            clientSocket2.Close();
        }

        private void waveSource_DataAvailable(object sender, WaveInEventArgs e)
        { 
            clientSocket2.Send(e.Buffer);
        }

        private void play_voice_DoWork(object sender, DoWorkEventArgs e)
        {
            WaveOut waveOut = new WaveOut();
            while (true)
            {
                byte[] date = new byte[3200];
                int count = clientSocket2.Receive(date);

                MemoryStream ms = new MemoryStream(date);
                IWaveProvider reader = new RawSourceWaveStream(ms, new WaveFormat(16000, 16, 1));
                waveOut.Init(reader);
                waveOut.Play();
            }
        }
    }
}
```

## Reference
### 遠端平台
* [【Unity3D】如何打开外部 exe 程序](https://blog.51cto.com/u_14137942/2736268)
* [Unity调起外部程序cmd.exe等](https://blog.csdn.net/weixin_33878457/article/details/94489201)
* [Unity讀存檔路徑 絕對路徑 相對路徑](https://www.youtube.com/watch?v=u4UflKPaLbM)

### 霧節點
* [Python多線程實戰：用socket和threading，編寫全雙工多人聊天室（詳細講解！！）](https://www.twblogs.net/a/5ef78e5cdf18513b2737877a)
* [socket问题：同一台机器上开多个client，连到同一个server，怎样知道server端recv来的数据是哪个client发的？](https://www.debugease.com/vc/3098025.html)
* [python多线程socket实现多个client连接一个server](https://blog.csdn.net/linxinfa/article/details/104001443)

### 語音通訊功能（C＃）
* [C#實現電腦麥克風錄音](https://walkonnet.com/archives/449804)
* [C# 实现语音聊天](https://www.cnblogs.com/yswenli/p/14353482.html)
* [[C#] NAudio 庫的各種常用使用方式: 播放 錄製 轉碼 音訊視覺化](https://iter01.com/598073.html)
* [C# NAudio錄音和播放音訊檔案-實時繪製音訊波形圖（從音訊流資料獲取，而非裝置獲取）](https://codingnote.cc/zh-tw/p/2762/)
* [Record input from NAudio WaveIn, and save the output to Byte Array](https://stackoverflow.com/questions/45697477/record-input-from-naudio-wavein-and-save-the-output-to-byte-array)
* [A Voice Chat Application in C#](https://www.codeproject.com/Articles/19485/A-Voice-Chat-Application-in-C)
* [TCP Audio Streamer and Player (Voice Chat over IP)](https://www.codeproject.com/Articles/482735/TCP-Audio-Streamer-and-Player-Voice-Chat-over-IP)
* [Naudio chat app buffer problem](https://www.codeproject.com/Questions/5255926/Naudio-chat-app-buffer-problem)
* [How can I play byte array of audio raw data using NAudio?](https://stackoverflow.com/questions/28792548/how-can-i-play-byte-array-of-audio-raw-data-using-naudio)