# 2022/04/26 單機實現AR演算法（1）
###### tags: `論文實做紀錄` `AR演算法`

## 實作環境
1. 電腦系統實作環境

|**項目**|**版本**|
|:---:|:---:|
|**Windows 11 教育版**|21H2|
|**Anaconda**|4.10.3|
|**pip**|21.2.2|
|**Python**|3.8.12|

2. 安裝的Python套件包

|**項目**|**版本**|**安裝指令**
|:---:|:---:|:---:
|**OpenCV**|4.5.5|conda install -c conda-forge opencv
|**OpenGL**|3.1.1a1|conda install -c anaconda pyopengl
|**NumPy**|1.22.3|（安裝OpenCV時已附帶安裝）
|**Pygame**|2.1.2|pip install pygame
|**Pillow**|9.0.1|conda install -c anaconda pillow

## 實作紀錄
### 獲取ArUco標籤圖像
利用OpenCV中的ArUco標籤作為AR的定位標籤，標籤如下圖所示，標籤生成方法如下。

![ArUco標籤](https://i.imgur.com/BvmGxRD.png)


1. **創建標記字典**
ArUco中包含了一些預設的字典，如下表所示。並使用`cv2.aruco.Dictionary_get()`生成標籤字典。例如以下函式皆為創建一個由50個標記組成的字典，且每個標記的大小為4x4。

|字典程式代碼|數字代號|字典程式代碼|數字代號
|:---:|:---:|:---:|:---:
|DICT_4X4_50|0|DICT_6X6_50|8
|DICT_4X4_100|1|DICT_6X6_100|9
|DICT_4X4_250|2|DICT_6X6_250|10
|DICT_4X4_1000|3|DICT_6X6_1000|11
|DICT_5X5_50|4|DICT_7X7_50|12
|DICT_5X5_100|5|DICT_7X7_100|13
|DICT_5X5_250|6|DICT_7X7_250|14
|DICT_5X5_1000|7|DICT_7X7_1000|15

```python=
dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)
dictionary = cv2.aruco.Dictionary_get(0)
```

2. **繪製標籤**
使用`cv2.aruco.drawMarker()`函式繪製標籤，如下所示。函式中的參數意義如下表所示。

```python=
markerImage = cv2.aruco.drawMarker(dictionary, id, sidePixels, borderBits)
```

|參數名稱|參數意義|
|:---:|:---
|markerImage|函示所生成的標籤影像
|dictionary|前述第1步所產生的ArUco標籤字典
|id|標籤的編號，範圍根據使用的字典而有所不同，如`DICT_4X4_50`的標籤id只有0至49
|sidePixels|創建的標籤圖像大小
|borderBits|標記邊框的粗細（自選參數，預設為1）

3. **儲存標籤影像**
使用`cv2.imwrite()`函式儲存標籤影像。相關參數意義不懂的話請自行Google。

```python=
cv2.imwrite("marker.png", markerImage)
```

### ArUco標籤辨識
使用ArUco內建的標籤辨識功能進行識別，將目標標籤以綠色矩形框選，並標示標籤id，辨識結果如下圖所述。標籤辨識步驟如下所述。

![ArUco標籤辨識結果](https://i.imgur.com/64CLddH.png)

1. **創建欲辨識的標籤字典以及辨識參數**
標籤字典由前述的`cv2.aruco.Dictionary_get()`進行創建，這裡就不再重複說明。辨識參數使用`cv2.aruco.DetectorParameters_create()`函式進行創建，用以後續辨識標籤。

```python=
parameters = cv2.aruco.DetectorParameters_create()
```

2. **設定並開啟相機**
使用OpenCV內建函式`cv2.VideoCapture()`獲取當前相機影像，並設定其影像解析度為1920x1080。

```python=
capture = cv2.VideoCapture(0)
capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
```

3. **獲取影像並進行影像處理**
使用`capture.read()`獲取相機影像，並將獲取的影像以`cv2.cvtColor()`函式進行灰階處理。

```python=
ret, frame = capture.read()
gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
```

4. **辨識標籤**
將前述的影像使用`cv2.aruco.detectMarkers()`進行標籤辨識，函示如下所示。函式中的參數意義如下表所示。

```python=
corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray_frame, dictionary, parameters=parameters)
```

|參數名稱|參數意義|
|:---:|:---
|corners|辨識出正確標籤的頂點位置
|ids|辨識出正確標籤於ArUco標籤字典中的編號
|rejected_corners|辨識出不正確標籤的頂點位置
|gray_frame|欲辨識的影像
|dictionary|ArUco標籤字典
|parameters|前述第1步所創建的辨識參數

5. **繪製辨識結果**
將前述的辨識結果使用`cv2.aruco.drawDetectedMarkers()`繪製辨識結果，並標示正確標籤的id，函式如下所示。函式中的參數意義如下表所示。

```python=
#繪製正確標籤
frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))
#繪製錯誤標籤
frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=rejected_corners, borderColor=(0, 0, 255))
```

|參數名稱|參數意義|
|:---:|:---
|frame|繪製完成的影像
|image|繪製辨識結果的基底影像
|corners|欲繪製框線的頂點資訊
|ids|辨識正確的標籤於ArUco標籤字典中的id
|borderColor|指定欲繪製框線的顏色

6. **顯示結果**
使用`cv2.imshow()`函式顯示繪製完成的影像，詳細不懂的話參數請自行Google。

```python=
cv2.imshow('frame', frame)
```

7. **實現影像串療效果**
將前述3至6步驟加入迴圈中，並撰寫退出邏輯，且在退出後釋放相機資源。程式如下所式。

```python=
while True:
    ret, frame = capture.read()
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray_frame, dictionary, parameters=parameters)
    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))
    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=rejected_corners, borderColor=(0, 0, 255))
    cv2.imshow('frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        cv2.imwrite("detectMarkers.png", frame)
        break
        
capture.release()
cv2.destroyAllWindows()
```

## 實作程式碼整理
```python=
import cv2

def save_tagimg(dictionary):
    markerImage = cv2.aruco.drawMarker(dictionary, 25, 200, 600, 1)
    
    cv2.imwrite("marker.png", markerImage)
    
dictionary = cv2.aruco.Dictionary_get(10) #創建ArUco標籤字典
save_tagimg(dictionary) #將ArUco標籤影像儲存到本機

parameters = cv2.aruco.DetectorParameters_create() #創建ArUco標籤辨識參數

capture = cv2.VideoCapture(0) #開啟相機

#設定相機解析度為1920*1080
capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

while True:
    ret, frame = capture.read()
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray_frame, dictionary, parameters=parameters) #辨識影像中的標籤
    
    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0)) #繪製正確的標籤
    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=rejected_corners, borderColor=(0, 0, 255)) #繪製錯誤的標籤
    
    cv2.imshow('frame', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        cv2.imwrite("detectMarkers.png", frame) #儲存最後一幀的影像（拍照截圖）
        break

#釋放相機占用的資源
capture.release()
cv2.destroyAllWindows()
```

## Reference
### [sourabhkhemka/Thirsty-Crow-E-yantra](https://github.com/sourabhkhemka/Thirsty-Crow-E-yantra/blob/master/GLteapot.py)
這篇是用OpenCV與OpenGL建構AR應用程式，以**Python**進行編程，但3D物件使用OpenGL內建的茶壺進行顯示，有對物件的遠近使用線性函數進行縮放。  
**附註：目前缺相機校正的數據（System.npz），所以無法直接執行。**

### [OpenCV-Python實戰（12）——一文詳解AR增强現實](https://pythonmana.com/2021/10/20211024210351384d.html)
用OpenCV進行AR應用開發，以**Python**進行編程，含有二維碼生成，並用期進行影校校正與相機姿態估計
