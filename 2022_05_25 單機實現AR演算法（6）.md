# 2022/05/25 單機實現AR演算法（6）
###### tags: `論文實做紀錄` `AR演算法`
## 實作環境
參考2022/04/26 單機實現AR演算法（1）的[實作環境](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。並另外於電腦中安裝了Solid Works 2018 教育版（[成大提供](https://www.cc.ncku.edu.tw/download/softwaredl.php?cate=SolidWorks)）與3ds Max 2023 教育版（[Autodesk官方提供](https://www.autodesk.com.cn/education/edu-software/overview?sorting=featured&filters=individual#card-3dsmax)）進行3D建模作業。

## 實作紀錄
### 3D建模
在本研究中需使用到各種不同的3D模型，除CNC已經由廠商事先進行建模（如下圖），其他標註用的3D模型需自行使用3D建模軟體進行建模。在這次實作中將使用Solid Works 2018 教育版進行3D建模，並使用3ds Max 2023 教育版將3D模型輸出為OBJ格式以方便後續程式讀取與使用。3D模型的建模步驟與需注意的重點如下所述。

![CNC的3D模型與實體照片](https://i.imgur.com/TNdNw53.jpg)

1. **3D建模**
於Solid Works中建立3D模型，如下圖所示，也可以使用自己熟悉的建模軟體進行建模作業。因後續Solid Works可以直接將模型以OBJ格式輸出，故在這邊使用Solid Works進行實作。

![Solid Works建模](https://i.imgur.com/zkJKkml.png)

<font color=#FF0000>**注意：**</font>在建模時須確保3D模型與模型世界座標原點的位置，若原點不再模型中的話，在後續使用OpenGL繪製模型時，會出現模型飄在空中的狀況，因為OBJ中所記錄的頂點位置皆是以模型世界座標為基準，這在OpenGL中也適用。

2. **輸出OBJ檔（Solid Works）**
在Solid Works中要輸出OBJ檔需先開啟**ScanTo3D**功能（工具→附加），如下圖所示。

![開啟ScanTo3D](https://i.imgur.com/Vurf4nh.png)

在**ScanTo3D**開啟後需重新開啟Solid Works以載入**ScanTo3D**設定，之後選擇另存新檔時，將存檔類型選擇**ScanTo3D(.obj)** ，就可以將檔案以OBJ格式輸出，如下圖所示。

![Solid Works輸出OBJ檔](https://i.imgur.com/R4jVCBA.png)

3. **輸出OBJ檔（3ds Max）**
因為廠商繪製的CNC模型檔案為IGS格式，Solid Works無法將IGS格式轉換為OBJ檔輸出，所以使用3ds Max進行轉檔輸出，如下圖所示。

![3ds Max轉檔](https://i.imgur.com/ciCV9x9.png)

OBJ檔時輸出時，可針對輸出結果進行調整，如模型縮放比例（Scale）、精度至小數點後第幾位（precision）等，在這邊我只將模型縮小至0.05倍進行輸出，如所示。

![3ds Max的OBJ輸出設定](https://i.imgur.com/BxQjgGk.png)

在輸出完成後會產生一個OBJ檔（*.obj）紀錄模型的頂點位置、法向量、平面、使用的平面材質等數據，並令外商一個MTL檔（*.mtl）紀錄平面材質資訊，當OBJ檔需使用材質時，會去MTL檔中尋找所需的材質資訊。其中OBJ檔可使用Windows的3D檢視器開啟，檢視模型渲染相關資訊，如下圖所示。

![3D模型檢視器-CNC模型](https://i.imgur.com/CQXrxRe.png)

### 渲染OBJ檔案模型
實作中將使用Pyhton語言讀取OBJ檔案中的頂點位置、法向量、平面等資訊，及其紀錄於MTL檔中的平面材質資訊，並將其輸入至OpenGL中進行影像渲染作業。在這次實作中參考了BryceQing/OPENCV_AR的OBJ讀取方法（[objloader.py](https://github.com/BryceQing/OPENCV_AR/blob/master/objloader.py)）進行讀取後，搭配之前的相機姿態估計、背景影像貼圖等實作（可參考[2022/05/08 單機實現AR演算法（5）](https://hackmd.io/@vf19961226/rJsOZBBLc)），如下圖所示，完成論文上描述之基礎AR演算法。程式步驟如下所述。

![AR OBJ影像渲染](https://i.imgur.com/29AO9qy.png)

1. **讀取OBJ檔**
讀取OBJ檔中模型的頂點位置頂點位置、法向量、平面、使用的平面材質等數據，並將其進行分類、轉換後，輸入OpenGL。OBJ檔與MTL檔中各項參數意義可參考[OpenGL 3D 繪圖互動程式設計](https://www.flag.com.tw/books/product/FT755)p12-50～p12-55。在程式如下所示。在程式中使用了pygame函式庫讀取模型的影像貼圖，並事先使用OpenGL建立貼圖，以方便後續調用，相關函式使用方式可參考[2022/05/08 單機實現AR演算法（5）](https://hackmd.io/@vf19961226/rJsOZBBLc)。

```python=
import pygame
from OpenGL.GL import *

def MTL(dir, filename):
    contents = {}
    mtl = None
    for line in open(dir + filename, "r"):
        if line.startswith('#'): continue
        values = line.split()
        if not values: continue
        if values[0] == 'newmtl':
            mtl = contents[values[1]] = {}
        elif mtl is None:
            raise (ValueError, "mtl file doesn't start with newmtl stmt")
        elif values[0] == 'map_Kd':
            # load the texture referred to by this declaration
            mtl[values[0]] = dir + values[1]
            surf = pygame.image.load(mtl['map_Kd'])
            image = pygame.image.tostring(surf, 'RGBA', 1)
            ix, iy = surf.get_rect().size
            texid = mtl['texture_Kd'] = glGenTextures(1)
            # print('texid', texid)
            # texid = 10
            glBindTexture(GL_TEXTURE_2D, texid)
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,
                GL_LINEAR)
            glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,
                GL_LINEAR)
            glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, ix, iy, 0, GL_RGBA,
                GL_UNSIGNED_BYTE, image)
        else:
            mtl[values[0]] = list(map(float, values[1:]))
    return contents

# TODO load more format models
class OBJ:
    def __init__(self, filename, swapyz=False):
        
        self.dir = filename[: filename.rfind('/') + 1]        
        
        """Loads a Wavefront OBJ file. """
        self.vertices = []
        self.normals = []
        self.texcoords = []
        self.faces = []

        material = None
        for line in open(filename, "r"):
            if line.startswith('#'): continue
            values = line.split()
            if not values: continue
            if values[0] == 'v':
                v = list(map(float, values[1:4]))
                if swapyz:
                    v = v[0], v[2], v[1]
                self.vertices.append(v)
            elif values[0] == 'vn':
                v = list(map(float, values[1:4]))
                if swapyz:
                    v = v[0], v[2], v[1]
                self.normals.append(v)
            elif values[0] == 'vt':
                self.texcoords.append(list(map(float, values[1:3])))
            elif values[0] in ('usemtl', 'usemat'):
                material = values[1]
                # print('debug values', values[1])
            elif values[0] == 'mtllib':
                self.mtl = MTL(self.dir, values[1])
            elif values[0] == 'f':
                face = []
                texcoords = []
                norms = []
                for v in values[1:]:
                    w = v.split('/')
                    face.append(int(w[0]))
                    if len(w) >= 2 and len(w[1]) > 0:
                        texcoords.append(int(w[1]))
                    else:
                        texcoords.append(0)
                    if len(w) >= 3 and len(w[2]) > 0:
                        norms.append(int(w[2]))
                    else:
                        norms.append(0)
                self.faces.append((face, norms, texcoords, material))
```

2. **輸入OpenGL**
帶讀取完OBJ的檔案資訊後，將其輸入OpenGL中建立一個渲染流程，可在日後需渲染該模型時直接調用該流程，可有效降低電腦每次渲染的負擔。首先利用`glGenLists()`函式創建新的渲染流程編號，接著將該編號用`glNewList()`創建新的渲染流程，之後再利用`glBindTexture()`、 `glColor3f()`等函式將表面材質資訊輸入渲染流程中，其中若要輸入頂點、法向量、平面等資訊的話，需使用`glBegin()`指定繪製平面的方式（可參考[OpenGL 3D 繪圖互動程式設計](https://www.flag.com.tw/books/product/FT755)p4-19），並在其與`glEnd()`之間使用`glNormal3fv()` 、`glTexCoord2fv()` 、`glVertex3fv()`等函式分別設定法向量、平面材質、平面等，最終使用`glEndList()`結束渲染流程定義。在程式如下所示。

```python=
self.gl_list = glGenLists(1)
glNewList(self.gl_list, GL_COMPILE)
glFrontFace(GL_CCW)
for face in self.faces:
    vertices, normals, texture_coords, material = face
    mtl = self.mtl[material]
    if 'texture_Kd' in mtl:
        # use diffuse texmap
        glBindTexture(GL_TEXTURE_2D, mtl['texture_Kd'])
    else:
        # just use diffuse colour
        glColor3f(*mtl['Kd'])
    glBegin(GL_POLYGON)            
    for i in range(len(vertices)):
        if normals[i] > 0:
            glNormal3fv(self.normals[normals[i] - 1])
        if texture_coords[i] > 0 and 'texture_Kd' in mtl:
            glTexCoord2fv(self.texcoords[texture_coords[i] - 1])
        glVertex3fv(self.vertices[vertices[i] - 1])
    glEnd()
glColor3f(1.0,1.0,1.0) # Clear the painting color.
glEndList()
```

3. **設定燈光**
為了使3D物件看起來更有立體感，加入燈光可以有效製造出陰影效果，可以凸顯物件的立體感。在本次實作中使用了`glLightfv()`函式來設定燈光，並於其中依序填入燈光編號、欲設定的燈光屬性、欲設定的參數值，設定完成後記得使用`glEnable()`開啟燈光功能（GL_LIGHTING）以及啟用設定好的燈光（GL_LIGHT0），並可以在不使用時使用`glDisable()`關閉。在程式如下所示。

```python=
glLightfv(GL_LIGHT0, GL_AMBIENT, (0.5, 0.5, 0.5, 1.0)) #設置環境光的屬性
glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.6, 0.6, 0.6, 1.0)) #設置環境光的散射屬性
glLightfv(GL_LIGHT0, GL_POSITION, (0.0, 0.0, 1.0, 1.0)) #設置環境光的位置
glEnable(GL_LIGHTING) #開啟燈光功能
glEnable(GL_LIGHT0) #開啟GL_LIGHT0燈光

glDisable(GL_LIGHT0) #關閉GL_LIGHT0燈光
```

4. **影像渲染**
調用`glCallList()`函式，可呼叫於第2步驟中設定的渲染流程，可以直接渲染剛剛輸入的OBJ檔模型，並將其與過去實做過的相機姿態估計、背景影像貼圖等結合（可參考[2022/05/08 單機實現AR演算法（5）](https://hackmd.io/@vf19961226/rJsOZBBLc)），就可以完成AR的基本程式。在程式如[程式碼整理](https://hackmd.io/aDllCoDmRhOGshNJFO4Heg?view#%E6%B8%B2%E6%9F%93OBJ%E6%AA%94%E6%A1%88%E6%A8%A1%E5%9E%8B1)所示。

## 程式碼整理
### 渲染OBJ檔案模型
```python=
from OpenGL.GLUT import *
from OpenGL.GLU import *
from OpenGL.GL import *

import cv2
import numpy as np
from ctypes import * #glVertexAttribPointer 最後一個數值需用ctypes格式，不然會跑不動
from PIL import Image #用來將影像轉換為OpenGL貼圖可輸入的格式

import objloader #用來讀取OBJ檔的py檔

W = 1280 #影像寬度
H = 720 #影像高度
FPS = 60 #影像影格率

#背景頂點渲染器程式（vs）
VERTEX_SHADER = """   
#version 410

layout(location = 0) in vec2 position;
layout(location = 1) in vec2 texcoord;

out vec2 coord;

void main()
{
	gl_Position = vec4(position, 0.0, 1.0);
	coord = texcoord;
}
"""
 
#背景片段渲染器程式（fs）
FRAGMENT_SHADER = """ 
#version 410

in vec2 coord;
out vec4 color;
uniform sampler2D tex;

void main(void)
{
	color = texture(tex, coord);
}
"""

# 設定相機取像資訊
cap = cv2.VideoCapture(0 + cv2.CAP_DSHOW) #cv2.CAP_DSHOW據說為Windows特有，不知道Linux需不需要，主要是拿來消除影像黑邊（0代表第一台相機）
cap.set(cv2.CAP_PROP_FRAME_WIDTH, W) #設定相機影像寬度
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, H) #設定相機影像高度
cap.set(cv2.CAP_PROP_FPS, FPS) #設定相機取像頻率

parameter = np.load('test_Camera_parameter.npz')
cameraMatrix = parameter['mtx']
distCoeffs = parameter['dist']

dictionary = cv2.aruco.Dictionary_get(10)
parameters = cv2.aruco.DetectorParameters_create()

def background_init(): #畫背景的buffer初始化，包含一些頂點甚麼之類的（program編號為1，Textures編號為1）
    glClearColor(1.0, 1.0, 1.0, 1.0)
    glEnable(GL_DEPTH_TEST)
    glDepthFunc(GL_LEQUAL)
    
    # Initialize shaders
    ########################
    program = glCreateProgram()
     
    vs = glCreateShader(GL_VERTEX_SHADER)
    fs = glCreateShader(GL_FRAGMENT_SHADER)
    
    glShaderSource(vs, VERTEX_SHADER)
    glShaderSource(fs, FRAGMENT_SHADER)
    
    glCompileShader(vs)
    glCompileShader(fs)
    
    glAttachShader(program, vs)
    glAttachShader(program, fs)
    
    glLinkProgram(program)
    
    # Define vertex
    ########################
    data2 = np.array([[-4, -3, 0, 1],
                     [4, -3, 1, 1],
                     [4, 3, 1, 0],
                     [-4, 3, 0, 0]], dtype = "float32") #[世界座標X軸, 世界座標Y軸, 視窗座標X軸, 視窗座標Y軸]
    
    data2 = data2.flatten()
    
    data = np.array([[1.0, -1.0, 1.0, 0.0],
                     [-1.0, -1.0, 0.0, 0.0],
                     [-1.0, 1.0, 0.0, 1.0],
                     [1.0, 1.0, 1.0, 1.0]], dtype = "float32") #[世界座標X軸, 世界座標Y軸, 視窗座標X軸, 視窗座標Y軸]
    
    data = data.flatten()
    
    # Create buffer
    ########################
    buffer = glGenBuffers(1)
    
    glBindBuffer(GL_ARRAY_BUFFER, buffer)
    
    glBufferData(GL_ARRAY_BUFFER, data.nbytes, data, GL_STATIC_DRAW)
    
    vao = glGenVertexArrays(1)
    glBindVertexArray(vao)
    
    glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 16, None)
    glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 16, c_void_p(8)) #位移一個元素4bit，共為一9個元素36bit，型別要用ctypes的c_void_p
    
    glEnableVertexAttribArray(0)
    glEnableVertexAttribArray(1)
    
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)

    texture = glGenTextures(1)
    glBindTexture(GL_TEXTURE_2D, texture)
    
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)
    
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, W, H, 0, GL_RGBA, GL_UNSIGNED_BYTE, None)

    glBindTexture(GL_TEXTURE_2D, 0)

def draw_background(img):
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
    
    tex_back = Image.fromarray(img)
    tex_back = tex_back.tobytes("raw","BGRX", 0, -1)
    
    glUseProgram(1)
    
    glBindTexture(GL_TEXTURE_2D, 1) #1是背景的貼圖渲染器
    glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, W, H, GL_RGBA, GL_UNSIGNED_BYTE, tex_back)
    glDrawArrays(GL_TRIANGLE_FAN, 0, 4)
    glClear(GL_DEPTH_BUFFER_BIT)
    glBindTexture(GL_TEXTURE_2D, 0) #0是內建的，用來取消綁定貼圖
    
    glUseProgram(0)

def extrinsic2ModelView(RVEC, TVEC, R_vector = True):
    """[Get modelview matrix from RVEC and TVEC]
    Arguments:
        RVEC {[vector]} -- [Rotation vector]
        TVEC {[vector]} -- [Translation vector]
    """

    R, _ = cv2.Rodrigues(RVEC)

    Rx = np.array([
        [1, 0, 0],
        [0, -1, 0],
        [0, 0, -1]
    ])

    TVEC = TVEC.flatten().reshape((3, 1))

    #transform_matrix = Rx @ np.hstack((R, TVEC))
    transform_matrix = np.dot(Rx, np.hstack((R, TVEC)))
    M = np.eye(4)
    
    M[:3, :] = transform_matrix
    return M.T.flatten()

def intrinsic2Project(MTX, width, height, near_plane=0.01, far_plane=100.0):
    """[Get ]
    Arguments:
        MTX {[np.array]} -- [The camera instrinsic matrix that you get from calibrating your chessboard]
        width {[float]} -- [width of viewport]]
        height {[float]} -- [height of viewport]
    Keyword Arguments:
        near_plane {float} -- [near_plane] (default: {0.01})
        far_plane {float} -- [far plane] (default: {100.0})
    Returns:
        [np.array] -- [1 dim array of project matrix]
    """
    P = np.zeros(shape=(4, 4), dtype=np.float32)

    fx, fy = MTX[0, 0], MTX[1, 1]
    cx, cy = MTX[0, 2], MTX[1, 2]

    P[0, 0] = 2 * fx / width
    P[1, 1] = 2 * fy / height
    P[2, 0] = 1 - 2 * cx / width
    P[2, 1] = 2 * cy / height - 1
    P[2, 2] = -(far_plane + near_plane) / (far_plane - near_plane)
    P[2, 3] = -1.0
    P[3, 2] = - (2 * far_plane * near_plane) / (far_plane - near_plane)

    return P.flatten()

def draw_obj(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 轉化為灰度圖像
    corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray, dictionary, parameters=parameters) # 檢測圖像中標記
    
    if ids is not None:
        # rvecs, tvecs分別是角點中每個標記的旋轉和平移向量
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)
        
        for rvec, tvec in zip(rvecs, tvecs):
            modelView = extrinsic2ModelView(rvec, tvec)
            projection = intrinsic2Project(cameraMatrix, W, H)
            
            glMatrixMode(GL_PROJECTION)
            glLoadIdentity()
            glMultMatrixf(projection)
        
            glMatrixMode(GL_MODELVIEW)
            glLoadIdentity()
            glLoadMatrixf(modelView)
            
            glEnable(GL_LIGHT0)
            glCallList(1) #沒意外編號是一
            glDisable(GL_LIGHT0)
            
def light_init():
    #加燈光
    glLightfv(GL_LIGHT0, GL_AMBIENT, (0.5, 0.5, 0.5, 1.0)) #設置環境光的屬性，0號
    glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.6, 0.6, 0.6, 1.0)) #設置環境光的散射屬性，0號
    glLightfv(GL_LIGHT0, GL_POSITION, (0.0, 0.0, 1.0, 1.0)) #設置環境光的位置，0號
    glEnable(GL_LIGHTING)
    glEnable(GL_LIGHT0)
            
def Display():
    ret, frame = cap.read()
    
    draw_background(frame)
    draw_obj(frame)
    
    glutSwapBuffers()
    
def main():
    # Initialize GLUT and GLEW, then create a window.
    ############################
    glutInit()
    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE | GLUT_DEPTH)
    
    glutInitWindowPosition(100, 100)
    glutInitWindowSize(W, H)
    glutCreateWindow(b"Background Buffer Test") # You cannot use OpenGL functions before this line; The OpenGL context must be created first by glutCreateWindow()!
    
    light_init() #燈光初始化
    background_init() #畫背景的buffer初始化，包含一些頂點甚麼之類的
    model = objloader.OBJ("CNC_test6.obj", swapyz = True) #讀取OBJ檔案，並且把它弄成一個渲染程序輸出
     
    #Register GLUT callback functions
    ############################
    glutDisplayFunc(Display)
    glutIdleFunc(Display)
    ############################
    
    # Enter main event loop.
    glutMainLoop()
    
if __name__ == "__main__":
    main()
```

## Reference
### 3D建模
[Solidworks如何另存为和打开OBJ文件](https://blog.csdn.net/acetaohai123123/article/details/78266948)

[ScanTo3D 概要-2018-SOLIDWORKS說明](https://help.solidworks.com/2018/chinese/SolidWorks/scanto3d/c_scanto3d_overview.htm)

### 渲染OBJ檔案模型
[BryceQing/OPENCV_AR/objloader.py](https://github.com/BryceQing/OPENCV_AR/blob/master/objloader.py)

[理解obj模型檔案的格式和每行的意義](https://www.w3help.cc/a/202109/890731.html)

[STL、PLY、OBJ格式分析](https://www.twblogs.net/a/5d4987b0bd9eee541c306ae2)

[如何将外部的obj模型导入OpenGL](https://www.cnblogs.com/feiquan/p/8207407.html)

[obj檔案[3D模型檔案格式]](https://www.easyatm.com.tw/wiki/obj%E6%AA%94%E6%A1%88)

[OpenGL glLightfv 函数的应用以及光源的相关知识](https://blog.csdn.net/chy19911123/article/details/46413121)

[OpenGL入門示例8——圖形平移、旋轉、縮放](https://www.796t.com/content/1547677263.html)