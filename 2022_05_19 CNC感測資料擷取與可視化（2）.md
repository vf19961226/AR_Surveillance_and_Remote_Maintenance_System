# 2022/05/19 CNC感測資料擷取與可視化（2）
###### tags: `論文實做紀錄` `AR使用者介面` `CNC數據處理`
## 實作環境
### 霧節點
1. 電腦系統實作環境

|**項目**|**版本**|
|:---:|:---:|
|**Windows 11 教育版**|21H2|
|**Anaconda**|4.10.3|
|**pip**|21.2.2|
|**Python**|3.8.12|

2. 安裝的Python套件包

|**項目**|**版本**|**安裝指令**
|:---:|:---:|:---:
|**opcua**|0.98.13|conda install -c conda-forge opcua
|**matplotlib**|3.5.2|conda install -c conda-forge matplotlib
|**NumPy**|1.21.5|conda install -c anaconda numpy
|**OpenCV**|4.5.5|conda install -c conda-forge opencv
|**Pillow**|8.2.0|conda install -c anaconda pillow

### 工業電腦
1. 電腦系統實作環境（[NISE 3800E-H110](https://www.nexcom.com.tw/Products/industrial-computing-solutions/industrial-fanless-computer/core-i-performance/fanless-pc-fanless-computer-nise-3800e-h110)）**（待確認）**

|**項目**|**版本**|
|:---:|:---:|
|**Windows 10**||
|**Visual Studio 2019**||
|**.NET**|3.1|

2. 安裝的NuGet套件

|**項目**|**版本**|**安裝指令**
|:---:|:---:|:---:
|**Opc.UaFx.Advanced**|2.26.0|（直接由NuGet套件管理頁面安裝）

### AR設備

1. 電腦系統實作環境（[Surface Pro 7 平板電腦](https://www.microsoft.com/zh-tw/surface/devices/surface-pro-7#techspecs)）

|**項目**|**版本**|
|:---:|:---:|
|**Windows 10 家用版**|20H2|
|**Visual Studio 2017**||
|**.NET**|4.7.1|

2. 安裝的NuGet套件

|**項目**|**版本**|**安裝指令**
|:---:|:---:|:---:
|**OpenCvSharp4**|4.5.5.20211231|（直接由NuGet套件管理頁面安裝）
|**OpenCvSharp4.Extensions**|4.5.5.20211231|（直接由NuGet套件管理頁面安裝）
|**OpenCvSharp4.runtime.win**|4.5.5.20211231|（直接由NuGet套件管理頁面安裝）

## 實作紀錄
本次實作延伸了[2022/05/14 CNC感測資料擷取與可視化（1）](https://hackmd.io/i_uw4tbTQGSgi--e4qKGnA?view#20220514-CNC%E6%84%9F%E6%B8%AC%E8%B3%87%E6%96%99%E6%93%B7%E5%8F%96%E8%88%87%E5%8F%AF%E8%A6%96%E5%8C%96%EF%BC%881%EF%BC%89)的進度，並將其與[2022/04/27 單機實現AR演算法（2）](https://hackmd.io/yT3kcorQQ-aOUcm4TvPo6g#20220427-%E5%96%AE%E6%A9%9F%E5%AF%A6%E7%8F%BEAR%E6%BC%94%E7%AE%97%E6%B3%95%EF%BC%882%EF%BC%89)所實現之AR影像顯示進行結合，主要是基於計畫辦公室期末審查與論文需求的實作。本次實作將著重於AR設備（Surface Pro 7 平板電腦）與霧節點間的影像傳輸，使用Socket通訊將AR設備影像傳送至霧節點進行影像處理後回傳，使現場人員可透過AR設備監控CNC即時狀態，未來將其與OpenGL進行結合，使本系統具備3D影像渲染能力，並依此發展論文中描述之遠端維修系統。以下將分別講述AR設備端與霧節點端之程式實現步驟。

### AR系統人機介面
本次實作於AR設備中建構一AR系統之人機介面，使用C＃於Visual Studio中以.NET架構進行Winform開發，並搭配OpenCvSharp套件擷取相機影像，並將其進行編碼與解碼，以利將影像透過Socket發送與接收影像後之顯示作業，本次實作介面如下圖所示。其詳細實作步驟如下所述。

![AR使用者介面](https://i.imgur.com/TO6qjQq.jpg)

1. **建立使用者介面**
使用Visual Studio圖形化介面建立本次實作之Winform介面，首先將Form中的FormBorderStyle屬性設為None以關閉Winform的外框，並將視窗大小設為愈顯示之影像解析度大小（在論文實作中希望將其大小設為全螢幕或1920×1080）。接著設置兩個按鈕，分別代表建立與斷開Socket之連線，並設置一PictureBox，用以顯示經由Socket回傳的影像，其大小將設置與Winform大小相同，以達到全螢幕的效果。最終設置一個Timer以固定時間間隔進行擷取像機影像、傳遞與接收影像、影像顯示等任務。本次實作使用之Winform控制項及其相關設定如下表所示。

|**控制項**|**控制項名稱（Name）**|**相關參數設置**|
|:---:|:---:|:---
|**Form**|AR_viewer| **FormBorderStyle：** None<br>**Text：** Suface AR Viewer<br>**Size：** 1280, 720
|**Button**|button3|**Text：** Connect
|**Button**|button1|**Text：** Disonnect
|**PictureBox**|pictureBox1|**Size：** 1280, 720 
|**Timer**|timer1|**Enabled：** False<br>**Interval：** 33

2. **建立Button事件**
本次實作於兩個Button中分別建立連線至Server並開始傳送影像、斷開與Server的連線並關閉視窗程式等兩個點擊事件。在button3的點擊事件中，我們需先創建一個影像擷取物件`cap`，並利用其`Open`方法開啟相機，因Windows本身系統問題，故需再相機辯號後面加上`VideoCaptureAPIs.DSHOW`參數，後續使用`cap.FrameHeight`與`cap.FrameWidth`修改的相機影像大小才會生效。在相機設定完成後接著設定Socket Client端的連線，首先建立一個Socket物件`clientSocket`，並利用其`Connect`方法與Server建立連線。事件最後啟動timer1計時器進行影像傳輸與接收作業，其相關程式碼將於第3步驟中進行敘述。程式如下所示。

```csharp=
private void button3_Click(object sender, EventArgs e)
{
    cap = new VideoCapture(0);
    cap.Open(0, VideoCaptureAPIs.DSHOW);
    cap.FrameHeight = 720;
    cap.FrameWidth = 1280;

    clientSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); //創建一個Socket物件（地址型別，流，協議型別）
    clientSocket.Connect(new IPEndPoint(IPAddress.Parse("127.0.0.1"), 7000)); //連線到Server（IP，Port）

    timer1.Enabled = true;
}
```
在button1點擊事件中，我們設計了斷開Socket Server連線`clientSocket.Close()`以及關閉本視窗程式`Application.Exit()`等兩項功能。程式如下所示。
```csharp=
private void button1_Click(object sender, EventArgs e)
{
    clientSocket.Close();
    Application.Exit();
}
```

3. **建立Timer事件**
在timer1的計時事件中，設計的程式可分為擷取相機影像、傳送影像、接收影像、顯示影像等四個步驟，首先使用影像擷取物件的`Read`方法擷取影像`img`，並設置一判斷式判斷相機取向使否正常，若不正常則關閉計時器。接著，將相機擷取之影像進行編碼`ImEncode`，轉換為byte格式以方便使用Socket傳送至霧節點進行影像處理運算`clientSocket.Send()`。在霧節點完成影像處理後，會將影像回傳至AR設備中，在AR設備中需使用Socket物件中的`Receive`方法接收霧節點回傳的影像數據，其中需設置一緩衝器`date`以接收回傳的影像數據（大小需大於回傳之影像大小，否則影像會毀損而無法解碼），並使用`Cv2.ImDecode()`進行影像解碼，將其由byte格式轉換為Mat影像格式。最終使用`OpenCvSharp.Extensions.BitmapConverter.ToBitmap()`函式將影像由Mat格式轉換為Bitmap格式，使其可於PictureBox中顯示`pictureBox1.Image`。程式如下所示。

```csharp=
private void timer1_Tick(object sender, EventArgs e)
{
    //擷取相機影像
    Mat img = new Mat();
    cap.Read(img);
    if (img.Empty()) timer1.Enabled = false;

    //傳送影像
    byte[] send_img = img.ImEncode();
    clientSocket.Send(send_img);

    //接收影像
    byte[] date = new byte[2000000];
    int count = clientSocket.Receive(date);
    ImreadModes mode = ImreadModes.Color;
    Mat image = Cv2.ImDecode(date, mode);

    //顯示影像
    Bitmap bit_img = OpenCvSharp.Extensions.BitmapConverter.ToBitmap(image);
    pictureBox1.Image = bit_img;
}
```

### 霧節點影像處理
本次實作將Socket Server部署於霧節點中，負責處理來自AR設備之現場影像，將其與CNC數據可視化結果進行整合，使其以AR的方式呈現給現場使用者。其影像處理方法已於[2022/04/27 單機實現AR演算法（2）](https://hackmd.io/yT3kcorQQ-aOUcm4TvPo6g#20220427-%E5%96%AE%E6%A9%9F%E5%AF%A6%E7%8F%BEAR%E6%BC%94%E7%AE%97%E6%B3%95%EF%BC%882%EF%BC%89)實作完成，另外可與[2022/05/14 CNC感測資料擷取與可視化（1）](https://hackmd.io/i_uw4tbTQGSgi--e4qKGnA#20220514-CNC%E6%84%9F%E6%B8%AC%E8%B3%87%E6%96%99%E6%93%B7%E5%8F%96%E8%88%87%E5%8F%AF%E8%A6%96%E5%8C%96%EF%BC%881%EF%BC%89)進行整合，但因電腦運算效能限制（數據可視化部分卡頓），故本次暫時沒有使用OpcUA進行資料擷取，但程使碼以撰寫於檔案中（已經註解掉），在未來將以多線程運算解決單一執行許卡頓問。本次實作紀錄將著重於Socket Server之影像傳輸部分。其詳細實作步驟如下所述。

1. **Socket Server初始化**
首先使用`socket.socket()`創建一個Socket物件，並指定`AF_INET`（Internet Protocol）family的通訊協定，類型使用`SOCK_STREAM`（Stream Socket）即TCP傳輸方式。接著以`setsockopt`方法進行Server相關設定，如使用基本套接字符介面`socket.SOL_SOCKET`、開啟或關閉地址複用功能`socket.SO_REUSEADDR`等，詳細可參考[setsockopt函数功能及参数详解](https://www.cnblogs.com/cthon/p/9270778.html)。接著就可以使用`bind`方法建立Server，並將其綁定至相應之IP地址`server_ip`與接口`socket_port`，最終使用`listen`方法設至Client連接上限為5個。程式如下所示。

```python=
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind((server_ip, socket_port))
s.listen(5)
```

2. **等待Client連線**
使用`accept`方法等待Client連線，並回傳連線物件`conn`以及Client的IP位置`addr`。程式如下所示。

```python=
conn, addr = s.accept()
```

3. **接收影像並解碼**
使用`conn.tecv()`等待Client回傳數據，括號中的數值代表緩衝器大小，該數值需大於回傳之影像大小，否則影像會毀損而無法解碼。在收到數據後使用`np.frombuffer()`函式將其解碼為Unit8編碼，並使著以`Image.open()`函式進行讀取，若讀取成功則將其轉換為OpenCV格式，並將影像紀錄至`open_cv_image2`變數中，若`Image.open()`函式無法讀取（代表傳輸數據有缺漏），則使用上一次正常的數據進行後續影像處理。程式如下所示。

```python=
indata = conn.recv(2000000)
data = np.frombuffer(indata, dtype='uint8')
try:
    image = Image.open(io.BytesIO(data))
    open_cv_image = np.array(image) 

    open_cv_image = open_cv_image[:, :, ::-1].copy() 
    open_cv_image2 = open_cv_image
except:
    open_cv_image = open_cv_image2
```

<font color=#808080>**註解：** 因使用OpenCV開啟有缺陷的影像，所產生的錯誤帶碼無法被Try-Except捕獲，會造成程式無法順利運行，所以這裡使用Pillow函式庫代替。</font>

4. **影像編碼並傳遞**
在影像處理完成後，將處理完成影像使用`cv2.imencode()`以JPG格式進行編碼，並將其轉換為Numpy矩陣後，轉換為byte格式，以`conn.send()`傳送至AR設備進行顯示。程式如下所示。

```python=
img_encode = cv2.imencode('.jpg', open_cv_image)[1]
data_encode = np.array(img_encode)
str_encode = data_encode.tobytes()
conn.send(str_encode)
```

5. **關閉Server**
在整個程式結束之後可使用`s.close()`函式來關閉Server。

```python=
s.close()
```

## 程式碼整理
### AR系統人機介面
```csharp=
using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;
//導入Socket
using System.Net.Sockets;
using System.Net;
//導入OpenCV
using OpenCvSharp;

namespace Surface_AR_Viewer
{
    public partial class AR_viewer : Form
    {
        public AR_viewer()
        {
            InitializeComponent();
        }

        Socket clientSocket;
        VideoCapture cap;

        private void button3_Click(object sender, EventArgs e)
        {
            cap = new VideoCapture(0);
            cap.Open(0, VideoCaptureAPIs.DSHOW);
            cap.FrameHeight = 720;
            cap.FrameWidth = 1280;

            clientSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp);
            clientSocket.Connect(new IPEndPoint(IPAddress.Parse("140.116.86.203"), 7000));

            timer1.Enabled = true;
            
        }

        private void button1_Click(object sender, EventArgs e)
        {
            clientSocket.Close();
            Application.Exit();
        }

        private void timer1_Tick(object sender, EventArgs e)
        {
            Mat img = new Mat();
            cap.Read(img);
            if (img.Empty()) timer1.Enabled = false;

            byte[] send_img = img.ImEncode();
            clientSocket.Send(send_img);
            
            byte[] date = new byte[2000000];
            int count = clientSocket.Receive(date);
            ImreadModes mode = ImreadModes.Color;
            Mat image = Cv2.ImDecode(date, mode);
            
            Bitmap bit_img = OpenCvSharp.Extensions.BitmapConverter.ToBitmap(image);
            pictureBox1.Image = bit_img;
            
        }
    }
}
```

### 霧節點影像處理
```python=
from opcua import Server, ua
import socket
import cv2
import numpy as np
import matplotlib.pyplot as plt
import time
from PIL import Image
import io

def draw_augmented_overlay(pts_1, overlay_image, image):
    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],
    [0, overlay_image.shape[0]]])
    M = cv2.getPerspectiveTransform(pts_2, pts_1)
    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))
    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)
    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)
    image_masked = cv2.bitwise_and(image, image, mask=mask)
    result = cv2.add(dst_image, image_masked)
    return result

server_ip = "127.0.0.1"
socket_port = 7000
opc_port = 4840

#ArUco Initial
dictionary = cv2.aruco.Dictionary_get(10) #創建ArUco標籤字典
parameters = cv2.aruco.DetectorParameters_create() #創建ArUco標籤辨識參數
parameter = np.load('Demo_Camera_parameter_20220518.npz')
cameraMatrix = parameter['mtx']
distCoeffs = parameter['dist']

test_img = cv2.imread('CNCDashborad0.png')

#Socket Initial
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind((server_ip, socket_port))
s.listen(5)

print('Socket server start at: %s:%s' % (server_ip, socket_port))
print('wait for connection...')

#OpcUA Initial
var_double = ua.Variant(0, ua.VariantType.Double)
var_int = ua.Variant(0, ua.VariantType.Int16)

server =Server()
url ="opc.tcp://" + server_ip + ":" + str(opc_port)
print('OpcUA server server start at: %s:%s' % (server_ip, opc_port))
server.set_endpoint(url)

name ="MY_FIRST_OPCUA_SERVER"
addspace =server.register_namespace(name)

node=server.get_objects_node()

Param=node.add_object(addspace,"CNC")

#設定參數節點
##主軸震動感測器
x_axis = Param.add_variable("ns=3;i=1", "x_axis", var_double)
y_axis = Param.add_variable("ns=3;i=2", "y_axis", var_double)
z_axis = Param.add_variable("ns=3;i=3", "z_axis", var_double)
current = Param.add_variable("ns=3;i=4", "current", var_double)

x_axis.set_writable()
y_axis.set_writable()
z_axis.set_writable()
current.set_writable()

##三軸位置
x_loc = Param.add_variable("ns=4;i=1", "x_loc", var_double)
y_loc = Param.add_variable("ns=4;i=2", "y_loc", var_double)
z_loc = Param.add_variable("ns=4;i=3", "z_loc", var_double)

x_loc.set_writable()
y_loc.set_writable()
z_loc.set_writable()

##三軸速度
x_velocity = Param.add_variable("ns=5;i=1", "x_velocity", var_int)
y_velocity = Param.add_variable("ns=5;i=2", "y_velocity", var_int)
z_velocity = Param.add_variable("ns=5;i=3", "z_velocity", var_int)

x_velocity.set_writable()
y_velocity.set_writable()
z_velocity.set_writable()

##三軸扭矩
x_torque = Param.add_variable("ns=6;i=1", "x_torque", var_int)
y_torque = Param.add_variable("ns=6;i=2", "y_torque", var_int)
z_torque = Param.add_variable("ns=6;i=3", "z_torque", var_int)

x_torque.set_writable()
y_torque.set_writable()
z_torque.set_writable()

##三軸錯誤代碼
x_errcode = Param.add_variable("ns=7;i=1", "x_errcode", var_double)
y_errcode = Param.add_variable("ns=7;i=2", "y_errcode", var_double)
z_errcode = Param.add_variable("ns=7;i=3", "z_errcode", var_double)

x_errcode.set_writable()
y_errcode.set_writable()
z_errcode.set_writable()

server.start() #開啟Server

xlabel = []
i = 1

x_axis_list = []
y_axis_list = []
z_axis_list = []
current_list = []

x_velocity_list = []
y_velocity_list = []
z_velocity_list = []

x_torque_list = []
y_torque_list = []
z_torque_list = []

time_fig = []

i = 0;
data_normal = True
data0 = 0

while True:
    conn, addr = s.accept()
    print('connected by ' + str(addr))
    
    while True:
        '''因為後面畫圖會卡頓，所以先註解掉，之後用多線程解決
        #OpcUA取資料
        x_axis_val = x_axis.get_value()
        y_axis_val = y_axis.get_value()
        z_axis_val = z_axis.get_value()
        current_val = current.get_value()
        
        x_loc_val = x_loc.get_value()
        y_loc_val = y_loc.get_value()
        z_loc_val = z_loc.get_value()
        
        x_velocity_val = x_velocity.get_value()
        y_velocity_val = y_velocity.get_value()
        z_velocity_val = z_velocity.get_value()
        
        x_torque_val = x_torque.get_value()
        y_torque_val = y_torque.get_value()
        z_torque_val = z_torque.get_value()
        
        x_errcode_val = x_errcode.get_value()
        y_errcode_val = y_errcode.get_value()
        z_errcode_val = z_errcode.get_value()
        
        x_axis_list.append(x_axis_val)
        y_axis_list.append(y_axis_val)
        z_axis_list.append(z_axis_val)
        current_list.append(current_val)
        
        x_velocity_list.append(x_velocity_val)
        y_velocity_list.append(y_velocity_val)
        z_velocity_list.append(z_velocity_val)
        
        x_torque_list.append(x_torque_val)
        y_torque_list.append(y_torque_val)
        z_torque_list.append(z_torque_val)
        
        localtime = time.localtime()
        result = time.strftime("%H:%M:%S", localtime)
        time_fig.append(result)
        
        if len(xlabel) <= 10:
            xlabel.append(i)
            i += 1
            
        else:
            x_axis_list.pop(0) #刪除陣列中的第一個元素
            y_axis_list.pop(0)
            z_axis_list.pop(0)
            current_list.pop(0)
            
            x_velocity_list.pop(0)
            y_velocity_list.pop(0)
            z_velocity_list.pop(0)
            
            x_torque_list.pop(0)
            y_torque_list.pop(0)
            z_torque_list.pop(0)
            
            time_fig.pop(0)
        '''
        indata = conn.recv(2000000)
        data = np.frombuffer(indata, dtype='uint8')
        try:
            image = Image.open(io.BytesIO(data))
            open_cv_image = np.array(image) 
            # Convert RGB to BGR 
            open_cv_image = open_cv_image[:, :, ::-1].copy() 
            open_cv_image2 = open_cv_image
        except:
            open_cv_image = open_cv_image2
            
        if open_cv_image is not None:
            #判斷有沒有ArUco標籤
            gray_img = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)
            corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray_img, dictionary, parameters=parameters) #辨識影像中的標籤
            if ids is not None: #如果有標籤就畫圖
                '''因為會卡頓，所以先註解掉，之後用多線程解決
                fig2, axes2 = plt.subplots(2, 2, figsize=(25,25))
                ax1 = axes2[0, 0]
                ax2 = axes2[0, 1]
                ax3 = axes2[1, 0]
                ax4 = axes2[1, 1]
                
                ax1.plot(xlabel, x_axis_list, label = "Vibration_X(mm/sec^2)", color = "red") #X軸資料,Y軸資料,標籤(圖例顯示),線的顏色
                ax1.plot(xlabel, y_axis_list, label = "Vibration_Y(mm/sec^2)", color = "green")
                ax1.plot(xlabel, z_axis_list, label = "Vibration_Z(mm/sec^2)", color = "blue")
                ax1.plot(xlabel, current_list, label = "Current(A)", color = "yellow")
                ax1.set_title("Spindle") #設定標題
                ax1.legend(loc='upper right') #設定圖例位置
                ax1.set_xlabel("Time")
                ax1.set_ylabel("Value")
                ax1.set_xticks(xlabel,time_fig, rotation = 45)
                
                ax2.plot(xlabel, x_velocity_list, label = "Velocity(mm/min)", color = "red")
                ax2.plot(xlabel, x_torque_list, label = "Torque(N-m)", color = "green")
                ax2.set_title("X-Axis\nLocation: " + str(x_loc_val) + " Error:" + str(x_errcode_val))
                ax2.legend(loc='upper right')
                ax2.set_xlabel("Time")
                ax2.set_ylabel("Value")
                ax2.set_xticks(xlabel,time_fig, rotation = 45)
                
                ax3.plot(xlabel, y_velocity_list, label = "Velocity(mm/min)", color = "red")
                ax3.plot(xlabel, y_torque_list, label = "Torque(N-m)", color = "green")
                ax3.set_title("Y-Axis\nLocation: " + str(y_loc_val) + " Error:" + str(y_errcode_val))
                ax3.legend(loc='upper right')
                ax3.set_xlabel("Time")
                ax3.set_ylabel("Value")
                ax3.set_xticks(xlabel,time_fig, rotation = 45)
                
                ax4.plot(xlabel, z_velocity_list, label = "Velocity(mm/min)", color = "red")
                ax4.plot(xlabel, z_torque_list, label = "Torque(N-m)", color = "green")
                ax4.set_title("Z-Axis\nLocation: " + str(z_loc_val) + " Error:" + str(z_errcode_val))
                ax4.legend(loc='upper right')
                ax4.set_xlabel("Time")
                ax4.set_ylabel("Value")
                ax4.set_xticks(xlabel,time_fig, rotation = 45)
                
                fig2.canvas.draw()
                fig2.tight_layout()
                data = np.frombuffer(fig2.canvas.tostring_rgb(), dtype=np.uint8)
                data = data.reshape(fig2.canvas.get_width_height()[::-1] + (3,))
                plt.close()
                time.sleep(1)
                
                #img = cv2.imread('figure.png')
                cv2.imshow('CNC Dashborad', data)
                if cv2.waitKey(1) == ord('q'):
                    break
                '''
                rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)
                desired_points = np.float32([[-1 / 2, 1 / 2, 0], [1 / 2, 1 / 2, 0], [1 / 2, -1 / 2, 0], [-1 / 2, -1 / 2, 0]]) * 10
                # 投影點
                projected_desired_points, jac = cv2.projectPoints(desired_points, rvecs[0], tvecs[0], cameraMatrix, distCoeffs)
                # 繪制投影點
                open_cv_image = draw_augmented_overlay(projected_desired_points, test_img, open_cv_image)
            '''
            #顯示完成影像處理的結果（Demo時可以使用，搭配最後一行的cv2.destroyAllWindows使用）
            cv2.imshow("Surface Image", open_cv_image)
            cv2.waitKey(1)
            '''
            if open_cv_image is not None:
                img_encode = cv2.imencode('.jpg', open_cv_image)[1]
                data_encode = np.array(img_encode)
                str_encode = data_encode.tobytes()
                conn.send(str_encode)
        
s.close()
cv2.destroyAllWindows()
```

## Reference
### AR系統人機介面
[C#如何設定Windows Form顯示為全螢幕模式](https://emn178.pixnet.net/blog/post/81770097)

[c#實現最簡單的socket通訊](https://iter01.com/537311.html)

[OpenCVSharp: Unable to load DLL 'OpenCvSharpExtern'](https://stackoverflow.com/questions/44105973/opencvsharp-unable-to-load-dll-opencvsharpextern)

[C# (CSharp) OpenCvSharp VideoCapture.Read Examples](https://csharp.hotexamples.com/examples/OpenCvSharp/VideoCapture/Read/php-videocapture-read-method-examples.html)

[Camera Resolution not going to max value #938](https://github.com/shimat/opencvsharp/issues/938)

[How can I convert Mat to Bitmap using OpenCVSharp?](https://stackoverflow.com/questions/37540750/how-can-i-convert-mat-to-bitmap-using-opencvsharp)

### 霧節點影像處理
[Python TCP Socket Server/Client 網路通訊教學](https://shengyu7697.github.io/python-tcp-socket/)

[用 socket 將 OpenCV 影像傳送到遠端 client](https://blog.maxkit.com.tw/2017/07/socket-opencv-client.html)

[libpng error处理方式](https://www.ai2news.com/blog/62131/)

[libpng error](https://blog.csdn.net/andylei777/article/details/78095411)

[Open PIL image from byte file](https://stackoverflow.com/questions/32908639/open-pil-image-from-byte-file)

[Convert image from PIL to openCV format](https://stackoverflow.com/questions/14134892/convert-image-from-pil-to-opencv-format)