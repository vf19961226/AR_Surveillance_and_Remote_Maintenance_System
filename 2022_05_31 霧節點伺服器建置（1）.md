# 2022/05/31 霧節點伺服器建置（1）
###### tags: `論文實做紀錄` `霧節點`
## 實作環境
 * 霧節點伺服器配置可參考2022/04/26 單機實現AR演算法（1）的[實作環境](https://hackmd.io/wpSYJl26Rw-ScjVlzjYwYw?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。
 * 工業電腦以及AR設備配置可參考2022/05/19 CNC感測資料擷取與可視化（2）的[實作環境](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q?view#%E5%AF%A6%E4%BD%9C%E7%92%B0%E5%A2%83)。

## 實作紀錄
本次實作主要將**單機實現AR演算法**與**CNC感測資料擷取與可視化**兩部分進行整合，並以Python多程序（Multiprocessing）優化系統，將依論文中各項功能模組分配各個程序所需執行的工作，在各個程序間以預先創建的隊列傳遞變數，使系統得以正常運行。在霧節點中的AR演算法已大致開發完成，並依照下圖中的架構，分別將Socket Server、影像分析（Image Analysis）、影像渲染（Image Shading）分散至不同的程序中，以加快系統運算速度，但尚未與霧節點資料庫進行整合（尚未建置）。

![AR 霧運算服務架構](https://i.imgur.com/ACSEnKn.png)

另外，本次實作已將下圖中除了**霧節點資料庫**以及**資料處理中的警報邏輯**外，其餘已經建置完成，並與前述的AR演算法進行整合。

![設備感測數據與AR演算法整合架構](https://i.imgur.com/FXC9rB6.png)

以下將針對不同程序及其功能進行說明。Python的多程序可參考[這篇文章](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/701565/)。

### Socket Server
本程序主要用以接收來自AR設備的現場影像，並將經過處理的AR影像回傳給AR設備。此部分程式碼主要參考2022/05/19 CNC感測資料擷取與可視化（2）的[霧節點影像處理](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q#%E9%9C%A7%E7%AF%80%E9%BB%9E%E5%BD%B1%E5%83%8F%E8%99%95%E7%90%86)，並加入隊列以方便與其他程序交換變數資料。其詳細實作步驟如下所述。

1. **創建初始化函式**
在Class的初始化函式中將變數初始化，如隊列、Server的IP和Port，並且將Socket Server初始化，以方便後續調用。程式如下所示。

```python=
def __init__(self, queue1, queue2, IP, PORT):
    super(Socket_Server, self).__init__()

    self.queue1 = queue1
    self.queue2 = queue2

    self.IP = IP
    self.PORT = PORT

    self.server_init()

def server_init(self):
    self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    self.s.bind((self.IP, self.PORT))
    self.s.listen(5)
```
<font color=#FF0000>**注意：**</font>使用Class創建多程序需繼承`multiprocessing.Process`，並在初始函式內使用`super`繼承自己class。

2. **啟動Server**
將已經初始化的Socket Server啟動，並接收來自AR設備的影像封包，將其解碼（`bytes2img()`）後，利用隊列（`queue1`）將影像傳送至影像分析程序進行後續處理。在影像處理完成後，會使用隊列（`queue2`）列將其回傳至Socket Server程序進行編碼（`img2bytes()`）後傳送至AR設備。程式如下所示。

```python=
def bytes2img(self, indata):
    data = np.frombuffer(indata, dtype='uint8')
    try:
        image = Image.open(io.BytesIO(data))
        open_cv_image = np.array(image) 
        # Convert RGB to BGR 
        open_cv_image = open_cv_image[:, :, ::-1].copy() 
        self.open_cv_image2 = open_cv_image
    except:
        open_cv_image = self.open_cv_image2

    if open_cv_image is not None:
        self.queue1.put(open_cv_image)

def img2bytes(self):
    img = self.queue2.get(True)

    img_encode = cv2.imencode('.jpg', img)[1]
    data_encode = np.array(img_encode)
    str_encode = data_encode.tobytes()

    return str_encode

def run(self):
    print("Socket_Server: {}".format(os.getpid()))
    while 1:
        conn, addr = self.s.accept()
        print('Connected by ' + str(addr))

        while 1:

            indata = conn.recv(2000000)
            self.bytes2img(indata)            
            outdata = self.img2bytes()
            conn.send(outdata)
```

### 影像分析（Image Analysis）
本程序主要是將Socket Server所接收到的影像進行分析，分析AR Uco標籤是否在影像中，並且估算相機與標籤的相對位置（相機姿態估計），若確認到有標籤於影像中，則將分析結果與影像傳送至影像渲染（Image Shading）程序進行影像渲染，反之，則將原始影像回傳至Socket Server。程式部分將參考2022/04/27 單機實現AR演算法（2）的[相機校正](https://hackmd.io/yT3kcorQQ-aOUcm4TvPo6g#%E7%9B%B8%E6%A9%9F%E6%A0%A1%E6%AD%A3)以及2022/05/05 單機實現AR演算法（4）的[OpenGL相機設定](https://hackmd.io/RUoE5QyxQ5ywffnHCvqi-w#OpenGL%E7%9B%B8%E6%A9%9F%E8%A8%AD%E5%AE%9A)。程式詳細實作步驟如下所述。

1. **創建初始化函式**
在Class的初始化函式中將變數初始化，如隊列以及相機矩陣。程式如下所示。

```python=
def __init__(self, queue1, queue2, queue3, CamMatrix_path):
    super(Image_Analysis, self).__init__()

    self.queue1 = queue1
    self.queue2 = queue2
    self.queue3 = queue3

    self.get_CamMatrix(CamMatrix_path)

def get_CamMatrix(self, file_path):
    parameter = np.load(file_path)
    self.cameraMatrix = parameter['mtx']
    self.distCoeffs = parameter['dist']
```

2. **影像分析**
透過隊列（`queue1`）接收來自Socket Server的影像，並使用`cv2.aruco.detectMarkers()`函式檢測AR Uco標籤是否在影像中，若有檢測到影像才會進行後續的影像分析，如相機姿態估計（`cv2.aruco.estimatePoseSingleMarkers()`）、生成塑模座標矩陣（`extrinsic2ModelView()`）與投影矩陣（`intrinsic2Project()`）、影像格式轉換（`convert2bgimg()`）等，最終將要傳遞至影像渲染程序的資料以字典的形式交由隊列（`queue2`）傳送。若沒有檢測到標籤，則直接將原始影像由列隊（`queue3`）回傳給Socket Server，使AR設備顯示原始影像。

```python=
def extrinsic2ModelView(self, RVEC, TVEC, R_vector = True):
    R, _ = cv2.Rodrigues(RVEC)

    Rx = np.array([
        [1, 0, 0],
        [0, -1, 0],
        [0, 0, -1]
    ])

    TVEC = TVEC.flatten().reshape((3, 1))

    transform_matrix = np.dot(Rx, np.hstack((R, TVEC)))
    M = np.eye(4)

    M[:3, :] = transform_matrix
    return M.T.flatten()

def intrinsic2Project(self, MTX, width, height, near_plane = 0.01, far_plane = 100.0):
    P = np.zeros(shape = (4, 4), dtype = np.float32)

    fx, fy = MTX[0, 0], MTX[1, 1]
    cx, cy = MTX[0, 2], MTX[1, 2]

    P[0, 0] = 2 * fx / width
    P[1, 1] = 2 * fy / height
    P[2, 0] = 1 - 2 * cx / width
    P[2, 1] = 2 * cy / height - 1
    P[2, 2] = -(far_plane + near_plane) / (far_plane - near_plane)
    P[2, 3] = -1.0
    P[3, 2] = - (2 * far_plane * near_plane) / (far_plane - near_plane)

    return P.flatten()

def convert2bgimg(self, img):
    bgimg = Image.fromarray(img)
    bgimg = bgimg.tobytes("raw","BGRX", 0, -1)

    return bgimg

def run(self):
    print("Image_Processing: {}".format(os.getpid()))

    dictionary = cv2.aruco.Dictionary_get(10)
    parameters = cv2.aruco.DetectorParameters_create()
    while 1:
        img = self.queue1.get(True)

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray, dictionary, parameters = parameters)
        if ids is not None:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, self.cameraMatrix, self.distCoeffs)
            for rvec, tvec in zip(rvecs, tvecs):
                modelView = self.extrinsic2ModelView(rvec, tvec)
                projection = self.intrinsic2Project(self.cameraMatrix, img.shape[1], img.shape[0])

            data = {"img" : self.convert2bgimg(img), "mv" : modelView, "pj" : projection}
            self.queue2.put(data)

        else:
            self.queue3.put(img)
```

### 影像渲染（Image Shading）
本程序主要用以渲染3D模型以及顯示CNC可視化資料，相較於2022/05/08 單機實現AR演算法（5）的[簡易AR測試](https://hackmd.io/7BBSM6HGQLyhR_TJAYFeXQ#%E7%B0%A1%E6%98%93AR%E6%B8%AC%E8%A9%A6)，本次將背景貼圖以調用緩衝器以及渲染器方式實現，連帶CNC可視化資料也是使用同一種方法實現。另外使用2022/05/25 單機實現AR演算法（6）的[渲染OBJ檔案模型](https://hackmd.io/aDllCoDmRhOGshNJFO4Heg#%E6%B8%B2%E6%9F%93OBJ%E6%AA%94%E6%A1%88%E6%A8%A1%E5%9E%8B)進行OBJ模型渲染，並且為使3D模型看起來更加擬真，因此加入了燈光效果。程式步驟如下所述。

1. **創建初始化函式**
在Class的初始化函式中將變數初始化，如隊列、影像長寬、OBJ模型路徑、渲染模型數量、渲染器的程式碼等，其中渲染器的程式碼是使用OpenGL渲染語言（OpenGL Shading Language，GLSL）進行撰寫，其語法可參考[GLSL 详解（基础篇）](https://colin1994.github.io/2017/11/11/OpenGLES-Lesson04/)或是[OpenGL 3D 繪圖互動程式設計](https://www.flag.com.tw/books/product/FT755)。程式如下所示。

```python=
def __init__(self, queue1, queue2, queue3, img_width, img_height, obj_file, obj_num, test = False):
    super(Image_Shading, self).__init__()

    self.queue1 = queue1
    self.queue2 = queue2
    self.queue3 = queue3

    self.W = img_width
    self.H = img_height

    self.obj_file = obj_file
    self.num = obj_num

    self.test = test

    self.BG_VERTEX_SHADER = """   
                            #version 410

                            layout(location = 0) in vec2 position;
                            layout(location = 1) in vec2 texcoord;

                            out vec2 coord;

                            void main()
                            {
                                gl_Position = vec4(position, 0.0, 1.0);
                                coord = texcoord;
                            }
                            """

    self.BG_FRAGMENT_SHADER = """
                            #version 410

                            in vec2 coord;
                            out vec4 color;
                            uniform sampler2D tex;

                            void main(void)
                            {
                                color = texture(tex, coord);
                            }
                            """

    self.DB_VERTEX_SHADER = """
                            #version 410

                            layout(location = 0) in vec2 position;
                            layout(location = 1) in vec2 texcoord;

                            uniform vec3 translate;
                            uniform mat4 move;
                            uniform mat4 modelview;
                            uniform mat4 projection;

                            out vec2 coord;

                            void main()
                            {
                                vec4 translate_model = vec4(position.x + translate.x, position.y + translate.y, 0.0 + translate.z, 1.0);
                                gl_Position = projection * modelview * move * translate_model;
                                coord = texcoord;
                            }
                            """

    self.DB_FRAGMENT_SHADER = """
                            #version 410

                            in vec2 coord;
                            out vec4 color;
                            uniform sampler2D tex;

                            void main(void)
                            {
                                color = texture(tex, coord);
                            }
                            """
```

2. **創建儀錶板渲染初始化函式**
本部分主要將儀表板渲染器與程式進行連結，程式如下所示。函式向功能意義可參考2022/05/05 單機實現AR演算法（4）的[影像渲染器（Shader）與緩衝器（Buffer）建置範例練習](https://hackmd.io/RUoE5QyxQ5ywffnHCvqi-w#%E5%BD%B1%E5%83%8F%E6%B8%B2%E6%9F%93%E5%99%A8%EF%BC%88Shader%EF%BC%89%E8%88%87%E7%B7%A9%E8%A1%9D%E5%99%A8%EF%BC%88Buffer%EF%BC%89%E5%BB%BA%E7%BD%AE%E7%AF%84%E4%BE%8B%E7%B7%B4%E7%BF%92)，貼圖部分（含渲染器）可參考[OpenGL 3D 繪圖互動程式設計](https://www.flag.com.tw/books/product/FT755)p11-7～p11-17。

```python=
def dashborad_init(self):
    glClearColor(1.0, 1.0, 1.0, 1.0)
    glEnable(GL_DEPTH_TEST)
    glDepthFunc(GL_LEQUAL)

    # Initialize shaders
    ########################
    self.db_program = glCreateProgram()

    db_vs = glCreateShader(GL_VERTEX_SHADER)
    db_fs = glCreateShader(GL_FRAGMENT_SHADER)

    glShaderSource(db_vs, self.DB_VERTEX_SHADER)
    glShaderSource(db_fs, self.DB_FRAGMENT_SHADER)

    glCompileShader(db_vs)
    glCompileShader(db_fs)

    glAttachShader(self.db_program, db_vs)
    glAttachShader(self.db_program, db_fs)

    glLinkProgram(self.db_program)

    glUseProgram(self.db_program)

    self.translate = glGetUniformLocation(self.db_program, "translate")
    self.move = glGetUniformLocation(self.db_program, "move")
    self.model_view = glGetUniformLocation(self.db_program, "modelview")
    self.projection = glGetUniformLocation(self.db_program, "projection")

    glUseProgram(0)

    # Define vertex
    ########################
    data = np.array([[0.5, -0.5, 1.0, 0.0],
                     [-0.5, -0.5, 0.0, 0.0],
                     [-0.5, 0.5, 0.0, 1.0],
                     [0.5, 0.5, 1.0, 1.0]], dtype = "float32") #[頂點座標X, 頂點座標Y, 貼圖座標X, 貼圖座標Y]

    data = data.flatten()

    # Create buffer
    ########################
    db_buffer = glGenBuffers(1)

    glBindBuffer(GL_ARRAY_BUFFER, db_buffer)

    glBufferData(GL_ARRAY_BUFFER, data.nbytes, data, GL_STATIC_DRAW)

    self.db_vao = glGenVertexArrays(1)
    glBindVertexArray(self.db_vao)

    glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 16, None)
    glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 16, c_void_p(8)) #位移一個元素4bit，共為一9個元素36bit，型別要用ctypes的c_void_p

    glEnableVertexAttribArray(0)
    glEnableVertexAttribArray(1)

    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)

    self.db_texture = glGenTextures(1) #創建一個貼圖緩衝器
    glBindTexture(GL_TEXTURE_2D, self.db_texture) #指定貼圖緩衝器為一個2為貼圖緩衝器

    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR) #指定貼圖型式
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)

    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, 640, 480, 0, GL_RGBA, GL_UNSIGNED_BYTE, None)

    glBindTexture(GL_TEXTURE_2D, 0)
    glBindVertexArray(0)
```
3. **創建儀錶板渲染函式**
透過隊列（`queue3`）接收來自數據處理（Data Processing）程序的CNC可視化數據，並將其根據不同的部件類別（主軸、X軸、Y軸、Z軸）進行平移、旋轉、縮放等操作，使其顯示於CNC的相對位置中，使現場人員可以直覺的發現數據異常。此部分之平移、旋轉、縮放等操作皆透過座標轉換矩陣進行運算，詳細可參考[OpenGL 3D 繪圖互動程式設計](https://www.flag.com.tw/books/product/FT755)第2-3節。程式如下所示。

```python=
def model_rotate_scaling(self, theta, axis, a = 1, b = 1, c = 1): #旋轉與縮放
    opt_matrix = np.eye(4) #opt_matrix初始化

    scaling = np.array([[a, 0, 0, 0],
                             [0, b, 0, 0],
                             [0, 0, c, 0],
                             [0, 0, 0, 1]], dtype = "float32") #縮放

    for t, a in zip(theta, axis): #旋轉
        t = t * np.pi / 180 #轉成弧度
        if a == 0: #X軸
            rotate = np.array([[1, 0, 0, 0],
                               [0, np.cos(t), -np.sin(t), 0],
                               [0, np.sin(t), np.cos(t), 0],
                               [0, 0, 0, 1]], dtype = "float32")

        elif a == 1: #Y軸
            rotate = np.array([[np.cos(t), 0, np.sin(t), 0],
                               [0, 1, 0, 0],
                               [-np.sin(t), 0, np.cos(t), 0],
                               [0, 0, 0, 1]], dtype = "float32")

        elif a == 2: #Z軸
            rotate = np.array([[np.cos(t), -np.sin(t), 0, 0],
                               [np.sin(t), np.cos(t), 0, 0],
                               [0, 0, 1, 0],
                               [0, 0, 0, 1]], dtype = "float32")

        opt_matrix = np.dot(rotate, opt_matrix)

    opt_matrix = np.dot(scaling, opt_matrix)

    opt_matrix = np.linalg.inv(opt_matrix)

    return opt_matrix.flatten()

def draw_dashborad(self, modelView, Projection):
    dashborads = self.queue3.get(True)
    dashborads_list = ["S", "X", "Y", "Z"]

    for i in dashborads_list:
        dashborad = dashborads[i]

        glUseProgram(self.db_program)
        glBindVertexArray(self.db_vao)

        glBindTexture(GL_TEXTURE_2D, self.db_texture)
        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, 640, 480, GL_RGBA, GL_UNSIGNED_BYTE, dashborad)

        if i == "S": #平移方式為直接輸入渲染器改變模型頂點位置
            glUniform3fv(self.translate, 1, np.array([0, 0, 0], dtype = "float32").flatten()) #平移[x, y, z]
        elif i == "X":
            glUniform3fv(self.translate, 1, np.array([0, 1.5, 0], dtype = "float32").flatten()) #平移[x, y, z]
        elif i == "Y":
            glUniform3fv(self.translate, 1, np.array([1.5, 0, 0], dtype = "float32").flatten()) #平移[x, y, z]
        elif i == "Z":
            glUniform3fv(self.translate, 1, np.array([1.5, 1.5, 0], dtype = "float32").flatten()) #平移[x, y, z]

        glUniformMatrix4fv(self.move, 1, GL_FALSE, self.model_rotate_scaling([0], [0], a = 0.5, b = 0.5)) #旋轉與縮放
        glUniformMatrix4fv(self.model_view, 1, GL_FALSE, modelView)
        glUniformMatrix4fv(self.projection, 1, GL_FALSE, Projection)

        glDrawArrays(GL_TRIANGLE_FAN, 0, 4)

        glBindTexture(GL_TEXTURE_2D, 0) #0是內建的，用來取消綁定貼圖

        glBindVertexArray(0)
        glUseProgram(0)
```
<font color=#FF0000>**注意：**</font>在使用渲染器時，須記得使用向對應之Program、VAO與貼圖緩衝器，否則出來的結果會不如預期，並養成在使用結束後取消綁定Program、VAO與貼圖緩衝器（指定為0）。

4. **創建背景渲染初始化函式**
背景部分創建方法與儀表板的方式相似，僅差在渲染器中沒有與塑模座標矩陣、投影矩陣相乘，故此貼圖會直接占滿整個OpenGL渲染畫面。程式如下所示。

```python=
def background_init(self):
    glClearColor(1.0, 1.0, 1.0, 1.0)
    glEnable(GL_DEPTH_TEST)
    glDepthFunc(GL_LEQUAL)

    # Initialize shaders
    ########################
    self.bg_program = glCreateProgram()

    bg_vs = glCreateShader(GL_VERTEX_SHADER)
    bg_fs = glCreateShader(GL_FRAGMENT_SHADER)

    glShaderSource(bg_vs, self.BG_VERTEX_SHADER)
    glShaderSource(bg_fs, self.BG_FRAGMENT_SHADER)

    glCompileShader(bg_vs)
    glCompileShader(bg_fs)

    glAttachShader(self.bg_program, bg_vs)
    glAttachShader(self.bg_program, bg_fs)

    glLinkProgram(self.bg_program)

    # Define vertex
    ########################       
    data = np.array([[1.0, -1.0, 1.0, 0.0],
                     [-1.0, -1.0, 0.0, 0.0],
                     [-1.0, 1.0, 0.0, 1.0],
                     [1.0, 1.0, 1.0, 1.0]], dtype = "float32")

    data = data.flatten()

    # Create buffer
    ########################
    bg_buffer = glGenBuffers(1)

    glBindBuffer(GL_ARRAY_BUFFER, bg_buffer)

    glBufferData(GL_ARRAY_BUFFER, data.nbytes, data, GL_STATIC_DRAW)

    self.bg_vao = glGenVertexArrays(1)
    glBindVertexArray(self.bg_vao)

    glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 16, None)
    glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 16, c_void_p(8)) #位移一個元素4bit，共為一9個元素36bit，型別要用ctypes的c_void_p

    glEnableVertexAttribArray(0)
    glEnableVertexAttribArray(1)

    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)

    self.bg_texture = glGenTextures(1)
    glBindTexture(GL_TEXTURE_2D, self.bg_texture)

    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)

    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, self.W, self.H, 0, GL_RGBA, GL_UNSIGNED_BYTE, None)

    glBindTexture(GL_TEXTURE_2D, 0)
    glBindVertexArray(0)
```

5. **創建背景渲染函式**
程式上與儀表板渲染函式相似，皆須將Program、VAO、貼圖緩衝器切換至相對應之參數。接著就可以將背景貼圖輸入後，並執行渲染指令`glDrawArrays()`，結束後再取消綁定Program、VAO、貼圖緩衝器。程式如下所示。

```python=
def draw_background(self, img):
    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)

    glUseProgram(self.bg_program)
    glBindVertexArray(self.bg_vao)

    glBindTexture(GL_TEXTURE_2D, self.bg_texture)
    glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, self.W, self.H, GL_RGBA, GL_UNSIGNED_BYTE, img)
    glDrawArrays(GL_TRIANGLE_FAN, 0, 4)
    glClear(GL_DEPTH_BUFFER_BIT)
    glBindTexture(GL_TEXTURE_2D, 0) #0是內建的，用來取消綁定貼圖

    glBindVertexArray(0) #0是內建的，用來取消綁定VAO
    glUseProgram(0)
```

6. **創建OBJ模型渲染函式**
因論文中需驗證AR影像處理運算卸載後之效益，將採用重複載入模型的方式增加系統運算負擔，而在顯示上為求美觀與凸顯渲染效果，因此本部分就將渲染出來的OBJ模型以方陣形式進行排列，並逾期中加入燈光效果，以凸顯3D模型之特徵。程式如下所示。

```python=
def draw_obj(self, modelView, projection):      
    i = 0 #計算現在渲染了幾個模型
    num_root =int(self.num ** 0.5) #對num開根號並取整數
    for x in range(num_root):
        for y in range(num_root):         
            glMatrixMode(GL_PROJECTION)
            glLoadIdentity()
            glMultMatrixf(projection)

            glMatrixMode(GL_MODELVIEW)
            glLoadIdentity()
            glLoadMatrixf(modelView)

            glTranslatef(x * 3.5, y * 3.5, 0) #X軸一個CNC距離為3.5，Y軸一個CNC距離為3.5（這個函式是移動模型位置的）

            glEnable(GL_LIGHT0)
            glCallList(i + 1)
            glDisable(GL_LIGHT0)

            i += 1

    if i != self.num: #如果前面的方陣沒有畫完
        x += 1
        for y in range(num_root):    
            glMatrixMode(GL_PROJECTION)
            glLoadIdentity()
            glMultMatrixf(projection)

            glMatrixMode(GL_MODELVIEW)
            glLoadIdentity()
            glLoadMatrixf(modelView)

            glTranslatef(x * 3.5, y * 3.5, 0) #X軸一個CNC距離為3.5，Y軸一個CNC距離為3.5（這個函式是移動模型位置的）

            glEnable(GL_LIGHT0)
            glCallList(i + 1)
            glDisable(GL_LIGHT0)
            i += 1
            if i == self.num: #如果畫完就跳出
                break

        if i != self.num: #如果前面的方陣沒有畫完
            y += 1
            for x in range(num_root):    
                glMatrixMode(GL_PROJECTION)
                glLoadIdentity()
                glMultMatrixf(projection)

                glMatrixMode(GL_MODELVIEW)
                glLoadIdentity()
                glLoadMatrixf(modelView)

                glTranslatef(x * 3.5, y * 3.5, 0) #X軸一個CNC距離為3.5，Y軸一個CNC距離為3.5（這個函式是移動模型位置的）

                glEnable(GL_LIGHT0)
                glCallList(i + 1)
                glDisable(GL_LIGHT0)
                i += 1
                if i == self.num: #如果畫完就跳出
                    break
```

7. **創建燈光初始化函式**
利用`glLightfv()`函式設定燈光屬性，如燈光位置、環境光的散射屬性、燈光屬性等參數，並透過`glEnable()`函式進行啟用，在後續使用時也是透過該函式進行調用。程式如下所示。

```python=
def light_init(self):
    #加燈光
    glLightfv(GL_LIGHT0, GL_AMBIENT, (0.5, 0.5, 0.5, 1.0)) #設置環境光的屬性，0號
    glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.6, 0.6, 0.6, 1.0)) #設置環境光的散射屬性，0號
    glLightfv(GL_LIGHT0, GL_POSITION, (0.0, 0.0, 1.0, 1.0)) #設置環境光的位置，0號
    glEnable(GL_LIGHTING)
    glEnable(GL_LIGHT0)
```

8. **影像渲染**
將上述函式依序填入啟動函式（`run`）與顯示函式（`Display`）中，在啟動函式需填入各項功能的初始化函式，並且將欲顯示的OBJ模型提淺導入至OpenGL中，之後就可以在顯示函式中進行渲染。在顯示函式中，將透過隊列（`queue1`）取得影像分析程序傳送之分析解果，並根據其結果進行影響渲染等相關運算，最終透過自行建置的`optimg`函式輸出OpenGL渲染影像成果，並用隊列（`queue2`）傳送至Socket Server，OpenGL影像輸出可參考2022/05/08 單機實現AR演算法（5）的[OpenGL影像輸出](https://hackmd.io/7BBSM6HGQLyhR_TJAYFeXQ?view#OpenGL%E5%BD%B1%E5%83%8F%E8%BC%B8%E5%87%BA)。程式如下所示。

```python=
def optimg(self):
    img_data = glReadPixels(0, 0, self.W, self.H, GL_BGRA, GL_FLOAT)
    img_data = np.frombuffer(img_data, np.float32)
    img_data.shape = self.H, self.W, 4
    img_data = img_data[::-1, :]
    if self.test:
        self.queue2.put(img_data)
    else:
        self.queue2.put(img_data * 255)

def Display(self):
    data = self.queue1.get(True)

    img = data["img"]
    modelView = data["mv"]
    projection = data["pj"]

    self.draw_background(img)
    self.draw_obj(modelView, projection)
    self.draw_dashborad(modelView, projection)

    self.optimg()

    glutSwapBuffers()

def run(self):
    print("Image_Shading: {}".format(os.getpid()))

    # Initialize GLUT and GLEW, then create a window.
    ############################
    glutInit()
    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE | GLUT_DEPTH)

    glutInitWindowPosition(100, 100)
    glutInitWindowSize(self.W, self.H)
    glutCreateWindow(b"Image of Augmented Reality") # You cannot use OpenGL functions before this line; The OpenGL context must be created first by glutCreateWindow()!

    self.light_init() #燈光初始化
    self.background_init() #畫背景的buffer初始化，包含一些頂點甚麼之類的
    self.dashborad_init() ###測試儀表板

    for i in range(self.num): #創建num個模型渲染
        objloader.OBJ(self.obj_file, swapyz = True) #讀取OBJ檔案，並且把它弄成一個渲染程序輸出

    #Register GLUT callback functions
    ############################
    glutDisplayFunc(self.Display)
    glutIdleFunc(self.Display)
    ############################

    # Enter main event loop.
    glutMainLoop()
```

### 數據處理（Data Processing）
本程序主要用以運行OPC UA Server，用其接收來自CNC的感測數據後，進行數據可式化作業，最終將可視化結果使用隊列傳送至影像渲染程序進行渲染。程式步驟如下所述。本續列程式主要參考[2022/05/14 CNC感測資料擷取與可視化（1）](https://hackmd.io/i_uw4tbTQGSgi--e4qKGnA)與[2022/05/19 CNC感測資料擷取與可視化（2）](https://hackmd.io/ayU0UBA4Qb-vM6oogoWz4Q)。

1. **創建初始化函式**
在Class的初始化函式中將變數初始化，如隊列、OPC UA Server IP和Port等。程式如下所示。

```python=
def __init__(self, queue, IP, PORT):
    super(Data_Processing, self).__init__()

    self.queue = queue

    self.IP = IP
    self.PORT = PORT
```

2. **數據可視化函式**
本次實作是使用`matplotlib`套件包將CNC感測數據可視化，並將其可視化數據由緩衝器中取出轉換為Numpy矩陣以利後續影像處理。程式如下所示。

```python=
def Draw_Dashborad(self, title, data):
    fig, ax = plt.subplots(figsize = (6.4, 4.8))

    if title == "Spindle":
        ax.plot(self.xlabel, data[0], label = "Vibration_X(mm/sec^2)", color = "red") #X軸資料,Y軸資料,標籤(圖例顯示),線的顏色
        ax.plot(self.xlabel, data[1], label = "Vibration_Y(mm/sec^2)", color = "green")
        ax.plot(self.xlabel, data[2], label = "Vibration_Z(mm/sec^2)", color = "blue")
        ax.plot(self.xlabel, data[3], label = "Current(A)", color = "yellow")
        ax.set_title(title) #設定標題

    else:
        ax.plot(self.xlabel, data[0], label = "Velocity(mm/min)", color = "red")
        ax.plot(self.xlabel, data[1], label = "Torque(N-m)", color = "green")
        ax.set_title(title + "\nLocation: " + str(data[2]) + " Error:" + str(data[3]))

    ax.legend(loc='upper right') #設定圖例位置
    ax.set_xlabel("Time")
    ax.set_ylabel("Value")
    ax.set_xticks(self.xlabel, self.time_fig, rotation = 45)

    fig.canvas.draw()
    dashborad = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    dashborad = dashborad.reshape(fig.canvas.get_width_height()[::-1] + (3,))
    plt.close()

    return dashborad
```

3. **資料擷取與處理**
創建OPC UA Server並將節點設定完成後，於迴圈中持續擷取新資料，並且調用數據可視化函式，最後使用自行建置的`convert2glimg`函式將可視化數據轉換為OpenGL可接受的影像格式，在用隊列（`queue`）將其傳送至影像渲染程序進行影像渲染。程式如下所示。

```python=
def convert2glimg(self, img):
    glimg = Image.fromarray(img)
    glimg = glimg.tobytes("raw","BGRX", 0, -1)

    return glimg

def run(self):
    print("Data_Processing: {}".format(os.getpid()))

    var_double = ua.Variant(0, ua.VariantType.Double)
    var_int = ua.Variant(0, ua.VariantType.Int16)

    server = Server()
    url ="opc.tcp://" + self.IP + ":" + str(self.PORT)
    print("OpcUA server server start at: %s:%s" % (self.IP, self.PORT))
    server.set_endpoint(url)

    name ="MY_FIRST_OPCUA_SERVER"
    addspace =server.register_namespace(name)

    node=server.get_objects_node()

    Param=node.add_object(addspace,"CNC")

    #設定參數節點
    ##主軸震動感測器
    x_axis = Param.add_variable("ns=3;i=1", "x_axis", var_double)
    y_axis = Param.add_variable("ns=3;i=2", "y_axis", var_double)
    z_axis = Param.add_variable("ns=3;i=3", "z_axis", var_double)
    current = Param.add_variable("ns=3;i=4", "current", var_double)

    x_axis.set_writable()
    y_axis.set_writable()
    z_axis.set_writable()
    current.set_writable()

    ##三軸位置
    x_loc = Param.add_variable("ns=4;i=1", "x_loc", var_double)
    y_loc = Param.add_variable("ns=4;i=2", "y_loc", var_double)
    z_loc = Param.add_variable("ns=4;i=3", "z_loc", var_double)

    x_loc.set_writable()
    y_loc.set_writable()
    z_loc.set_writable()

    ##三軸速度
    x_velocity = Param.add_variable("ns=5;i=1", "x_velocity", var_int)
    y_velocity = Param.add_variable("ns=5;i=2", "y_velocity", var_int)
    z_velocity = Param.add_variable("ns=5;i=3", "z_velocity", var_int)

    x_velocity.set_writable()
    y_velocity.set_writable()
    z_velocity.set_writable()

    ##三軸扭矩
    x_torque = Param.add_variable("ns=6;i=1", "x_torque", var_int)
    y_torque = Param.add_variable("ns=6;i=2", "y_torque", var_int)
    z_torque = Param.add_variable("ns=6;i=3", "z_torque", var_int)

    x_torque.set_writable()
    y_torque.set_writable()
    z_torque.set_writable()

    ##三軸錯誤代碼
    x_errcode = Param.add_variable("ns=7;i=1", "x_errcode", var_double)
    y_errcode = Param.add_variable("ns=7;i=2", "y_errcode", var_double)
    z_errcode = Param.add_variable("ns=7;i=3", "z_errcode", var_double)

    x_errcode.set_writable()
    y_errcode.set_writable()
    z_errcode.set_writable()

    server.start() #開啟Server

    i = 1
    self.xlabel = []
    self.time_fig = []

    x_axis_list = []
    y_axis_list = []
    z_axis_list = []
    current_list = []

    x_velocity_list = []
    y_velocity_list = []
    z_velocity_list = []

    x_torque_list = []
    y_torque_list = []
    z_torque_list = []

    while 1:
        #OpcUA取資料
        x_axis_val = x_axis.get_value()
        y_axis_val = y_axis.get_value()
        z_axis_val = z_axis.get_value()
        current_val = current.get_value()

        x_loc_val = x_loc.get_value()
        y_loc_val = y_loc.get_value()
        z_loc_val = z_loc.get_value()

        x_velocity_val = x_velocity.get_value()
        y_velocity_val = y_velocity.get_value()
        z_velocity_val = z_velocity.get_value()

        x_torque_val = x_torque.get_value()
        y_torque_val = y_torque.get_value()
        z_torque_val = z_torque.get_value()

        x_errcode_val = x_errcode.get_value()
        y_errcode_val = y_errcode.get_value()
        z_errcode_val = z_errcode.get_value()

        x_axis_list.append(x_axis_val)
        y_axis_list.append(y_axis_val)
        z_axis_list.append(z_axis_val)
        current_list.append(current_val)

        x_velocity_list.append(x_velocity_val)
        y_velocity_list.append(y_velocity_val)
        z_velocity_list.append(z_velocity_val)

        x_torque_list.append(x_torque_val)
        y_torque_list.append(y_torque_val)
        z_torque_list.append(z_torque_val)

        localtime = time.localtime()
        result = time.strftime("%H:%M:%S", localtime)
        self.time_fig.append(result)

        if len(self.xlabel) <= 10:
            self.xlabel.append(i)
            i += 1

        else:
            x_axis_list.pop(0) #刪除陣列中的第一個元素
            y_axis_list.pop(0)
            z_axis_list.pop(0)
            current_list.pop(0)

            x_velocity_list.pop(0)
            y_velocity_list.pop(0)
            z_velocity_list.pop(0)

            x_torque_list.pop(0)
            y_torque_list.pop(0)
            z_torque_list.pop(0)

            self.time_fig.pop(0)

        Spindle_Dashborad = self.Draw_Dashborad("Spindle", [x_axis_list, y_axis_list, z_axis_list, current_list])
        X_Dashborad = self.Draw_Dashborad("X-Axis", [x_velocity_list, x_torque_list, x_loc_val, x_errcode_val])
        Y_Dashborad = self.Draw_Dashborad("Y-Axis", [y_velocity_list, y_torque_list, y_loc_val, y_errcode_val])
        Z_Dashborad = self.Draw_Dashborad("Z-Axis", [z_velocity_list, z_torque_list, z_loc_val, z_errcode_val])

        self.queue.put({"S": self.convert2glimg(Spindle_Dashborad), "X": self.convert2glimg(X_Dashborad), "Y": self.convert2glimg(Y_Dashborad), "Z": self.convert2glimg(Z_Dashborad)})

    server.stop()
```
<font color=#FF0000>**注意：**</font>無法將OPC UA Server使用一個函式將其包起來，因為其中節點部分無法使用self，使用self會強制將節點物件變更為**變數**形式，從而導致程式報錯。

### 主程式（main）
主程式主要用以啟動上述的程序，並且創建隊列提供各個程序間進行變數交換。在主程式中另外撰寫了兩個測試用的class，分別是測試多程序的`test`以及代替Socket Server接收影像改為使用本地相機影像的`get_local_img`，以下將一一進行分述。

1. **test**
主要用以接收Socket Server程序傳送過來的影像，並將其轉換為灰階格式後回傳。詳細可直接參考本文的程式碼整理。
2. **get_local_img**
主要使用本地相機的影像取代Socket Server接收的AR設備影像進行測試，並將接收影像處理完的結果進行顯示。詳細可直接參考本文的程式碼整理。

3. **主程式**
透過創建隊列並輸入至個個程序的初始化函式中，之後將其使用`start()`啟動各個程序，之後呼叫`join()`以等待個個子程序執行結束才結束主程序。程式如下所示。

```python=
if __name__ == "__main__":
    SS2IA = Queue() #Socket Server傳送至影像分析的隊列
    IA2IS = Queue() #影像分析傳送至影像渲染的隊列
    IS2SS = Queue() #影像渲染傳送至Socket Server的隊列
    DP2IS = Queue() #數據處理傳送至影像渲染的隊列
    
    p1 = Socket_Server.Socket_Server(SS2IA, IS2SS, "140.116.86.220", 7000)
    p2 = Image_Analysis.Image_Analysis(SS2IA, IA2IS, IS2SS, "Camera_Calibration/Demo_Camera_parameter_20220518.npz")
    #p3 = Image_Shading.Image_Shading(IA2IS, IS2SS, DP2IS, 1280, 720, "OBJ_File/CNC_test6.obj", 1)
    p3 = Image_Shading2_Dashborad.Image_Shading(IA2IS, IS2SS, DP2IS, 1280, 720, "OBJ_File/CNC_test6.obj", 1) #測試儀錶板
    p4 = Data_Processing.Data_Processing(DP2IS, "140.116.86.220", 4840)
    
    p1.start()
    p2.start()
    p3.start()
    p4.start()
    
    p1.join()
    p2.join()
    p3.join()
    p4.join()
```

* 一次渲染多個CNC模型成果
使用`Image_Shading.Image_Shading()`函式，並將渲染數量改為24。

![渲染24個CNC模型](https://i.imgur.com/P0zqdsU.png)

* CNC感測數據AR可視化成果（模擬）
使用`get_local_img()`使用本地相機影像，將CNC可視化數據使用`Image_Shading2_Dashborad.Image_Shading()`函式進行渲染。（未來會將其與`Image_Shading.Image_Shading()`進行整合）

![CNC感測數據AR可視化](https://i.imgur.com/8SdnL92.png)


## 程式碼整理
### Socket Server
```python=
import os
import io
import socket
import cv2
import numpy as np
from PIL import Image
from multiprocessing import Process

class Socket_Server(Process):
    def __init__(self, queue1, queue2, IP, PORT):
        super(Socket_Server, self).__init__()
        
        self.queue1 = queue1
        self.queue2 = queue2
        
        self.IP = IP
        self.PORT = PORT
        
        self.server_init()
        
    def server_init(self):
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.s.bind((self.IP, self.PORT))
        self.s.listen(5)
        
    def bytes2img(self, indata):
        data = np.frombuffer(indata, dtype='uint8')
        try:
            image = Image.open(io.BytesIO(data))
            open_cv_image = np.array(image) 

            open_cv_image = open_cv_image[:, :, ::-1].copy() 
            self.open_cv_image2 = open_cv_image
        except:
            open_cv_image = self.open_cv_image2
        
        if open_cv_image is not None:
            self.queue1.put(open_cv_image)
            
    def img2bytes(self):
        img = self.queue2.get(True)
        
        img_encode = cv2.imencode('.jpg', img)[1]
        data_encode = np.array(img_encode)
        str_encode = data_encode.tobytes()
        
        return str_encode

    def run(self):
        print("Socket_Server: {}".format(os.getpid()))
        while 1:
            conn, addr = self.s.accept()
            print('Connected by ' + str(addr))
            
            while 1:
                
                indata = conn.recv(2000000)
                self.bytes2img(indata)            
                outdata = self.img2bytes()
                conn.send(outdata)
```

### 影像分析（Image Analysis）
```python=
import os
import cv2
import numpy as np
from PIL import Image
from multiprocessing import Process

import time

class Image_Analysis(Process):
    def __init__(self, queue1, queue2, queue3, CamMatrix_path):
        super(Image_Analysis, self).__init__() #需要繼承父類別的的東東
        
        self.queue1 = queue1
        self.queue2 = queue2
        self.queue3 = queue3
        
        self.get_CamMatrix(CamMatrix_path)
        
    def get_CamMatrix(self, file_path):
        parameter = np.load(file_path)
        self.cameraMatrix = parameter['mtx']
        self.distCoeffs = parameter['dist']
        
    def extrinsic2ModelView(self, RVEC, TVEC, R_vector = True):
        R, _ = cv2.Rodrigues(RVEC)
    
        Rx = np.array([
            [1, 0, 0],
            [0, -1, 0],
            [0, 0, -1]
        ])
    
        TVEC = TVEC.flatten().reshape((3, 1))
    
        #transform_matrix = Rx @ np.hstack((R, TVEC))
        transform_matrix = np.dot(Rx, np.hstack((R, TVEC)))
        M = np.eye(4)
        
        M[:3, :] = transform_matrix
        return M.T.flatten()
    
    def intrinsic2Project(self, MTX, width, height, near_plane = 0.01, far_plane = 100.0):
        P = np.zeros(shape = (4, 4), dtype = np.float32)
    
        fx, fy = MTX[0, 0], MTX[1, 1]
        cx, cy = MTX[0, 2], MTX[1, 2]
    
        P[0, 0] = 2 * fx / width
        P[1, 1] = 2 * fy / height
        P[2, 0] = 1 - 2 * cx / width
        P[2, 1] = 2 * cy / height - 1
        P[2, 2] = -(far_plane + near_plane) / (far_plane - near_plane)
        P[2, 3] = -1.0
        P[3, 2] = - (2 * far_plane * near_plane) / (far_plane - near_plane)
    
        return P.flatten()
    
    def convert2bgimg(self, img):
        bgimg = Image.fromarray(img)
        bgimg = bgimg.tobytes("raw","BGRX", 0, -1)
        
        return bgimg
    
    def run(self):
        print("Image_Processing: {}".format(os.getpid()))
        
        dictionary = cv2.aruco.Dictionary_get(10)
        parameters = cv2.aruco.DetectorParameters_create()
        while 1:
            img = self.queue1.get(True)
            
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            corners, ids, rejected_corners = cv2.aruco.detectMarkers(gray, dictionary, parameters = parameters)
            if ids is not None:
                rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, self.cameraMatrix, self.distCoeffs)
                for rvec, tvec in zip(rvecs, tvecs):
                    modelView = self.extrinsic2ModelView(rvec, tvec)
                    projection = self.intrinsic2Project(self.cameraMatrix, img.shape[1], img.shape[0])
                    
                data = {"img" : self.convert2bgimg(img), "mv" : modelView, "pj" : projection}
                self.queue2.put(data)
                
            else:
                self.queue3.put(img)
```

### 影像渲染（Image Shading）
```python=
import os
import numpy as np
from ctypes import *
from OpenGL.GLUT import *
from OpenGL.GLU import *
from OpenGL.GL import *
from multiprocessing import Process

import objloader

class Image_Shading(Process):
    def __init__(self, queue1, queue2, queue3, img_width, img_height, obj_file, obj_num, test = False):
        super(Image_Shading, self).__init__()
        
        self.queue1 = queue1
        self.queue2 = queue2
        self.queue3 = queue3
        
        self.W = img_width
        self.H = img_height
        
        self.obj_file = obj_file
        self.num = obj_num
        
        self.test = test
        
        self.BG_VERTEX_SHADER = """   
                                #version 410
                                
                                layout(location = 0) in vec2 position;
                                layout(location = 1) in vec2 texcoord;
                                
                                out vec2 coord;
                                
                                void main()
                                {
                                	gl_Position = vec4(position, 0.0, 1.0);
                                	coord = texcoord;
                                }
                                """
                            
        self.BG_FRAGMENT_SHADER = """
                                #version 410
                                
                                in vec2 coord;
                                out vec4 color;
                                uniform sampler2D tex;
                                
                                void main(void)
                                {
                                	color = texture(tex, coord);
                                }
                                """
                                
        self.DB_VERTEX_SHADER = """
                                #version 410
                                
                                layout(location = 0) in vec2 position;
                                layout(location = 1) in vec2 texcoord;
                                
                                uniform vec3 translate;
                                uniform mat4 move;
                                uniform mat4 modelview;
                                uniform mat4 projection;
                                
                                out vec2 coord;
                                
                                void main()
                                {
                                    vec4 translate_model = vec4(position.x + translate.x, position.y + translate.y, 0.0 + translate.z, 1.0);
                                	gl_Position = projection * modelview * move * translate_model;
                                	coord = texcoord;
                                }
                                """
                            
        self.DB_FRAGMENT_SHADER = """
                                #version 410
                                
                                in vec2 coord;
                                out vec4 color;
                                uniform sampler2D tex;
                                
                                void main(void)
                                {
                                	color = texture(tex, coord);
                                }
                                """
        
    def model_rotate_scaling(self, theta, axis, a = 1, b = 1, c = 1):
        opt_matrix = np.eye(4)
        
        scaling = np.array([[a, 0, 0, 0],
                                 [0, b, 0, 0],
                                 [0, 0, c, 0],
                                 [0, 0, 0, 1]], dtype = "float32")
        
        for t, a in zip(theta, axis):
            t = t * np.pi / 180
            if a == 0:
                rotate = np.array([[1, 0, 0, 0],
                                   [0, np.cos(t), -np.sin(t), 0],
                                   [0, np.sin(t), np.cos(t), 0],
                                   [0, 0, 0, 1]], dtype = "float32")
                
            elif a == 1:
                rotate = np.array([[np.cos(t), 0, np.sin(t), 0],
                                   [0, 1, 0, 0],
                                   [-np.sin(t), 0, np.cos(t), 0],
                                   [0, 0, 0, 1]], dtype = "float32")
                
            elif a == 2:
                rotate = np.array([[np.cos(t), -np.sin(t), 0, 0],
                                   [np.sin(t), np.cos(t), 0, 0],
                                   [0, 0, 1, 0],
                                   [0, 0, 0, 1]], dtype = "float32")
                
            opt_matrix = np.dot(rotate, opt_matrix)
            
        opt_matrix = np.dot(scaling, opt_matrix)
        
        opt_matrix = np.linalg.inv(opt_matrix)
        
        return opt_matrix.flatten()
        
    def dashborad_init(self):
        glClearColor(1.0, 1.0, 1.0, 1.0)
        glEnable(GL_DEPTH_TEST)
        glDepthFunc(GL_LEQUAL)

        self.db_program = glCreateProgram()
         
        db_vs = glCreateShader(GL_VERTEX_SHADER)
        db_fs = glCreateShader(GL_FRAGMENT_SHADER)
        
        glShaderSource(db_vs, self.DB_VERTEX_SHADER)
        glShaderSource(db_fs, self.DB_FRAGMENT_SHADER)
        
        glCompileShader(db_vs)
        glCompileShader(db_fs)
        
        glAttachShader(self.db_program, db_vs)
        glAttachShader(self.db_program, db_fs)
        
        glLinkProgram(self.db_program)
        
        glUseProgram(self.db_program)
        
        self.translate = glGetUniformLocation(self.db_program, "translate")
        self.move = glGetUniformLocation(self.db_program, "move")
        self.model_view = glGetUniformLocation(self.db_program, "modelview")
        self.projection = glGetUniformLocation(self.db_program, "projection")
        
        glUseProgram(0)

        data = np.array([[0.5, -0.5, 1.0, 0.0],
                         [-0.5, -0.5, 0.0, 0.0],
                         [-0.5, 0.5, 0.0, 1.0],
                         [0.5, 0.5, 1.0, 1.0]], dtype = "float32")
        
        data = data.flatten()

        db_buffer = glGenBuffers(1)
        
        glBindBuffer(GL_ARRAY_BUFFER, db_buffer)
        
        glBufferData(GL_ARRAY_BUFFER, data.nbytes, data, GL_STATIC_DRAW)
        
        self.db_vao = glGenVertexArrays(1)
        glBindVertexArray(self.db_vao)
        
        glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 16, None)
        glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 16, c_void_p(8))
        
        glEnableVertexAttribArray(0)
        glEnableVertexAttribArray(1)
        
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
    
        self.db_texture = glGenTextures(1)
        glBindTexture(GL_TEXTURE_2D, self.db_texture)
        
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)
        
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, 640, 480, 0, GL_RGBA, GL_UNSIGNED_BYTE, None)
    
        glBindTexture(GL_TEXTURE_2D, 0)
        glBindVertexArray(0)
              
    def draw_dashborad(self, modelView, Projection):
        dashborads = self.queue3.get(True)
        dashborads_list = ["S", "X", "Y", "Z"]
        
        for i in dashborads_list:
            dashborad = dashborads[i]
            
            glUseProgram(self.db_program)
            glBindVertexArray(self.db_vao)
            
            glBindTexture(GL_TEXTURE_2D, self.db_texture)
            glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, 640, 480, GL_RGBA, GL_UNSIGNED_BYTE, dashborad)

            if i == "S":
                glUniform3fv(self.translate, 1, np.array([0, 0, 0], dtype = "float32").flatten())
            elif i == "X":
                glUniform3fv(self.translate, 1, np.array([0, 1.5, 0], dtype = "float32").flatten())
            elif i == "Y":
                glUniform3fv(self.translate, 1, np.array([1.5, 0, 0], dtype = "float32").flatten())
            elif i == "Z":
                glUniform3fv(self.translate, 1, np.array([1.5, 1.5, 0], dtype = "float32").flatten())
                
            glUniformMatrix4fv(self.move, 1, GL_FALSE, self.model_rotate_scaling([0], [0], a = 0.5, b = 0.5))
            glUniformMatrix4fv(self.model_view, 1, GL_FALSE, modelView)
            glUniformMatrix4fv(self.projection, 1, GL_FALSE, Projection)
            
            glDrawArrays(GL_TRIANGLE_FAN, 0, 4)
            
            glBindTexture(GL_TEXTURE_2D, 0)
            
            glBindVertexArray(0)
            glUseProgram(0)
            
    def background_init(self):
        glClearColor(1.0, 1.0, 1.0, 1.0)
        glEnable(GL_DEPTH_TEST)
        glDepthFunc(GL_LEQUAL)

        self.bg_program = glCreateProgram()
         
        bg_vs = glCreateShader(GL_VERTEX_SHADER)
        bg_fs = glCreateShader(GL_FRAGMENT_SHADER)
        
        glShaderSource(bg_vs, self.BG_VERTEX_SHADER)
        glShaderSource(bg_fs, self.BG_FRAGMENT_SHADER)
        
        glCompileShader(bg_vs)
        glCompileShader(bg_fs)
        
        glAttachShader(self.bg_program, bg_vs)
        glAttachShader(self.bg_program, bg_fs)
        
        glLinkProgram(self.bg_program)
               
        data = np.array([[1.0, -1.0, 1.0, 0.0],
                         [-1.0, -1.0, 0.0, 0.0],
                         [-1.0, 1.0, 0.0, 1.0],
                         [1.0, 1.0, 1.0, 1.0]], dtype = "float32") 
        
        data = data.flatten()

        bg_buffer = glGenBuffers(1)
        
        glBindBuffer(GL_ARRAY_BUFFER, bg_buffer)
        
        glBufferData(GL_ARRAY_BUFFER, data.nbytes, data, GL_STATIC_DRAW)
        
        self.bg_vao = glGenVertexArrays(1)
        glBindVertexArray(self.bg_vao)
        
        glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 16, None)
        glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 16, c_void_p(8))
        
        glEnableVertexAttribArray(0)
        glEnableVertexAttribArray(1)
        
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
    
        self.bg_texture = glGenTextures(1)
        glBindTexture(GL_TEXTURE_2D, self.bg_texture)
        
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)
        
        glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, self.W, self.H, 0, GL_RGBA, GL_UNSIGNED_BYTE, None)
    
        glBindTexture(GL_TEXTURE_2D, 0)
        glBindVertexArray(0)
        
    def draw_background(self, img):
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        
        glUseProgram(self.bg_program)
        glBindVertexArray(self.bg_vao)
        
        glBindTexture(GL_TEXTURE_2D, self.bg_texture)
        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, self.W, self.H, GL_RGBA, GL_UNSIGNED_BYTE, img)
        glDrawArrays(GL_TRIANGLE_FAN, 0, 4)
        glClear(GL_DEPTH_BUFFER_BIT)
        glBindTexture(GL_TEXTURE_2D, 0)
        
        glBindVertexArray(0)
        glUseProgram(0)
        
    def draw_obj(self, modelView, projection):      
        i = 0
        num_root =int(self.num ** 0.5)
        for x in range(num_root):
            for y in range(num_root):         
                glMatrixMode(GL_PROJECTION)
                glLoadIdentity()
                glMultMatrixf(projection)
            
                glMatrixMode(GL_MODELVIEW)
                glLoadIdentity()
                glLoadMatrixf(modelView)
                
                glTranslatef(x * 3.5, y * 3.5, 0)     
                glEnable(GL_LIGHT0)
                glCallList(i + 1)
                glDisable(GL_LIGHT0)
                
                i += 1
                
        if i != self.num:
            x += 1
            for y in range(num_root):    
                glMatrixMode(GL_PROJECTION)
                glLoadIdentity()
                glMultMatrixf(projection)
            
                glMatrixMode(GL_MODELVIEW)
                glLoadIdentity()
                glLoadMatrixf(modelView)
                
                glTranslatef(x * 3.5, y * 3.5, 0)
                        
                glEnable(GL_LIGHT0)
                glCallList(i + 1)
                glDisable(GL_LIGHT0)
                i += 1
                if i == self.num:
                    break
            
            if i != self.num:
                y += 1
                for x in range(num_root):    
                    glMatrixMode(GL_PROJECTION)
                    glLoadIdentity()
                    glMultMatrixf(projection)
                
                    glMatrixMode(GL_MODELVIEW)
                    glLoadIdentity()
                    glLoadMatrixf(modelView)
                    
                    glTranslatef(x * 3.5, y * 3.5, 0)       
                    glEnable(GL_LIGHT0)
                    glCallList(i + 1)
                    glDisable(GL_LIGHT0)
                    i += 1
                    if i == self.num:
                        break
    
    def optimg(self):
        img_data = glReadPixels(0, 0, self.W, self.H, GL_BGRA, GL_FLOAT)
        img_data = np.frombuffer(img_data, np.float32)
        img_data.shape = self.H, self.W, 4
        img_data = img_data[::-1, :]
        if self.test:
            self.queue2.put(img_data)
        else:
            self.queue2.put(img_data * 255)
        
    def light_init(self):
        glLightfv(GL_LIGHT0, GL_AMBIENT, (0.5, 0.5, 0.5, 1.0))
        glLightfv(GL_LIGHT0, GL_DIFFUSE, (0.6, 0.6, 0.6, 1.0))
        glLightfv(GL_LIGHT0, GL_POSITION, (0.0, 0.0, 1.0, 1.0))
        glEnable(GL_LIGHTING)
        glEnable(GL_LIGHT0)
        
    def Display(self):
        data = self.queue1.get(True)
        
        img = data["img"]
        modelView = data["mv"]
        projection = data["pj"]
        
        self.draw_background(img)
        self.draw_obj(modelView, projection)
        self.draw_dashborad(modelView, projection)
        
        self.optimg()
        
        glutSwapBuffers()
        
    def run(self):
        print("Image_Shading: {}".format(os.getpid()))
        
        glutInit()
        glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE | GLUT_DEPTH)
        
        glutInitWindowPosition(100, 100)
        glutInitWindowSize(self.W, self.H)
        glutCreateWindow(b"Image of Augmented Reality")
        
        self.light_init()
        self.background_init()
        self.dashborad_init()
        
        for i in range(self.num):
            objloader.OBJ(self.obj_file, swapyz = True)
            
        glutDisplayFunc(self.Display)
        glutIdleFunc(self.Display)

        glutMainLoop()
```

### 數據處理（Data Processing）
```python=
from multiprocessing import Process
from opcua import Server, ua
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import os
import time

class Data_Processing(Process):
    def __init__(self, queue, IP, PORT):
        super(Data_Processing, self).__init__()
        
        self.queue = queue
        
        self.IP = IP
        self.PORT = PORT
        
    def OPC_Server_Init(self):
        var_double = ua.Variant(0, ua.VariantType.Double)
        var_int = ua.Variant(0, ua.VariantType.Int16)
        
        server =Server()
        url ="opc.tcp://" + self.IP + ":" + str(self.PORT)
        print("OpcUA server server start at: %s:%s" % (self.IP, self.PORT))
        server.set_endpoint(url)
        
        name ="MY_FIRST_OPCUA_SERVER"
        addspace =server.register_namespace(name)
        
        node=server.get_objects_node()
        
        Param=node.add_object(addspace,"CNC")

        self.x_axis = Param.add_variable("ns=3;i=1", "x_axis", var_double)
        self.y_axis = Param.add_variable("ns=3;i=2", "y_axis", var_double)
        self.z_axis = Param.add_variable("ns=3;i=3", "z_axis", var_double)
        self.current = Param.add_variable("ns=3;i=4", "current", var_double)
        
        self.x_axis.set_writable()
        self.y_axis.set_writable()
        self.z_axis.set_writable()
        self.current.set_writable()

        self.x_loc = Param.add_variable("ns=4;i=1", "x_loc", var_double)
        self.y_loc = Param.add_variable("ns=4;i=2", "y_loc", var_double)
        self.z_loc = Param.add_variable("ns=4;i=3", "z_loc", var_double)
        
        self.x_loc.set_writable()
        self.y_loc.set_writable()
        self.z_loc.set_writable()

        self.x_velocity = Param.add_variable("ns=5;i=1", "x_velocity", var_int)
        self.y_velocity = Param.add_variable("ns=5;i=2", "y_velocity", var_int)
        self.z_velocity = Param.add_variable("ns=5;i=3", "z_velocity", var_int)
        
        self.x_velocity.set_writable()
        self.y_velocity.set_writable()
        self.z_velocity.set_writable()

        self.x_torque = Param.add_variable("ns=6;i=1", "x_torque", var_int)
        self.y_torque = Param.add_variable("ns=6;i=2", "y_torque", var_int)
        self.z_torque = Param.add_variable("ns=6;i=3", "z_torque", var_int)
        
        self.x_torque.set_writable()
        self.y_torque.set_writable()
        self.z_torque.set_writable()

        self.x_errcode = Param.add_variable("ns=7;i=1", "x_errcode", var_double)
        self.y_errcode = Param.add_variable("ns=7;i=2", "y_errcode", var_double)
        self.z_errcode = Param.add_variable("ns=7;i=3", "z_errcode", var_double)
        
        self.x_errcode.set_writable()
        self.y_errcode.set_writable()
        self.z_errcode.set_writable()
        
        server.start()

    def Draw_Dashborad(self, title, data):
        fig, ax = plt.subplots(figsize = (6.4, 4.8))
        
        if title == "Spindle":
            ax.plot(self.xlabel, data[0], label = "Vibration_X(mm/sec^2)", color = "red")
            ax.plot(self.xlabel, data[1], label = "Vibration_Y(mm/sec^2)", color = "green")
            ax.plot(self.xlabel, data[2], label = "Vibration_Z(mm/sec^2)", color = "blue")
            ax.plot(self.xlabel, data[3], label = "Current(A)", color = "yellow")
            ax.set_title(title)
            
        else:
            ax.plot(self.xlabel, data[0], label = "Velocity(mm/min)", color = "red")
            ax.plot(self.xlabel, data[1], label = "Torque(N-m)", color = "green")
            ax.set_title(title + "\nLocation: " + str(data[2]) + " Error:" + str(data[3]))
        
        ax.legend(loc='upper right')
        ax.set_xlabel("Time")
        ax.set_ylabel("Value")
        ax.set_xticks(self.xlabel, self.time_fig, rotation = 45)
        
        fig.canvas.draw()
        dashborad = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        dashborad = dashborad.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        plt.close()

        return dashborad
        
    def Alarm_Logic(self):
        pass
    
    def Data_Analysis(self):
        pass
    
    def convert2glimg(self, img):
        glimg = Image.fromarray(img)
        glimg = glimg.tobytes("raw","BGRX", 0, -1)
        
        return glimg
        
    def run(self):
        print("Data_Processing: {}".format(os.getpid()))
        
        var_double = ua.Variant(0, ua.VariantType.Double)
        var_int = ua.Variant(0, ua.VariantType.Int16)
        
        server = Server()
        url ="opc.tcp://" + self.IP + ":" + str(self.PORT)
        print("OpcUA server server start at: %s:%s" % (self.IP, self.PORT))
        server.set_endpoint(url)
        
        name ="MY_FIRST_OPCUA_SERVER"
        addspace =server.register_namespace(name)
        
        node=server.get_objects_node()
        
        Param=node.add_object(addspace,"CNC")
        
        x_axis = Param.add_variable("ns=3;i=1", "x_axis", var_double)
        y_axis = Param.add_variable("ns=3;i=2", "y_axis", var_double)
        z_axis = Param.add_variable("ns=3;i=3", "z_axis", var_double)
        current = Param.add_variable("ns=3;i=4", "current", var_double)
        
        x_axis.set_writable()
        y_axis.set_writable()
        z_axis.set_writable()
        current.set_writable()

        x_loc = Param.add_variable("ns=4;i=1", "x_loc", var_double)
        y_loc = Param.add_variable("ns=4;i=2", "y_loc", var_double)
        z_loc = Param.add_variable("ns=4;i=3", "z_loc", var_double)
        
        x_loc.set_writable()
        y_loc.set_writable()
        z_loc.set_writable()

        x_velocity = Param.add_variable("ns=5;i=1", "x_velocity", var_int)
        y_velocity = Param.add_variable("ns=5;i=2", "y_velocity", var_int)
        z_velocity = Param.add_variable("ns=5;i=3", "z_velocity", var_int)
        
        x_velocity.set_writable()
        y_velocity.set_writable()
        z_velocity.set_writable()

        x_torque = Param.add_variable("ns=6;i=1", "x_torque", var_int)
        y_torque = Param.add_variable("ns=6;i=2", "y_torque", var_int)
        z_torque = Param.add_variable("ns=6;i=3", "z_torque", var_int)
        
        x_torque.set_writable()
        y_torque.set_writable()
        z_torque.set_writable()

        x_errcode = Param.add_variable("ns=7;i=1", "x_errcode", var_double)
        y_errcode = Param.add_variable("ns=7;i=2", "y_errcode", var_double)
        z_errcode = Param.add_variable("ns=7;i=3", "z_errcode", var_double)
        
        x_errcode.set_writable()
        y_errcode.set_writable()
        z_errcode.set_writable()
        
        server.start()
        
        i = 1
        self.xlabel = []
        self.time_fig = []
        
        x_axis_list = []
        y_axis_list = []
        z_axis_list = []
        current_list = []
        
        x_velocity_list = []
        y_velocity_list = []
        z_velocity_list = []
        
        x_torque_list = []
        y_torque_list = []
        z_torque_list = []
        
        while 1:
            x_axis_val = x_axis.get_value()
            y_axis_val = y_axis.get_value()
            z_axis_val = z_axis.get_value()
            current_val = current.get_value()
            
            x_loc_val = x_loc.get_value()
            y_loc_val = y_loc.get_value()
            z_loc_val = z_loc.get_value()
            
            x_velocity_val = x_velocity.get_value()
            y_velocity_val = y_velocity.get_value()
            z_velocity_val = z_velocity.get_value()
            
            x_torque_val = x_torque.get_value()
            y_torque_val = y_torque.get_value()
            z_torque_val = z_torque.get_value()
            
            x_errcode_val = x_errcode.get_value()
            y_errcode_val = y_errcode.get_value()
            z_errcode_val = z_errcode.get_value()
            
            x_axis_list.append(x_axis_val)
            y_axis_list.append(y_axis_val)
            z_axis_list.append(z_axis_val)
            current_list.append(current_val)
            
            x_velocity_list.append(x_velocity_val)
            y_velocity_list.append(y_velocity_val)
            z_velocity_list.append(z_velocity_val)
            
            x_torque_list.append(x_torque_val)
            y_torque_list.append(y_torque_val)
            z_torque_list.append(z_torque_val)
            
            localtime = time.localtime()
            result = time.strftime("%H:%M:%S", localtime)
            self.time_fig.append(result)
            
            if len(self.xlabel) <= 10:
                self.xlabel.append(i)
                i += 1
                
            else:
                x_axis_list.pop(0)
                y_axis_list.pop(0)
                z_axis_list.pop(0)
                current_list.pop(0)
                
                x_velocity_list.pop(0)
                y_velocity_list.pop(0)
                z_velocity_list.pop(0)
                
                x_torque_list.pop(0)
                y_torque_list.pop(0)
                z_torque_list.pop(0)
                
                self.time_fig.pop(0)
                
            Spindle_Dashborad = self.Draw_Dashborad("Spindle", [x_axis_list, y_axis_list, z_axis_list, current_list])
            X_Dashborad = self.Draw_Dashborad("X-Axis", [x_velocity_list, x_torque_list, x_loc_val, x_errcode_val])
            Y_Dashborad = self.Draw_Dashborad("Y-Axis", [y_velocity_list, y_torque_list, y_loc_val, y_errcode_val])
            Z_Dashborad = self.Draw_Dashborad("Z-Axis", [z_velocity_list, z_torque_list, z_loc_val, z_errcode_val])

            self.queue.put({"S": self.convert2glimg(Spindle_Dashborad), "X": self.convert2glimg(X_Dashborad), "Y": self.convert2glimg(Y_Dashborad), "Z": self.convert2glimg(Z_Dashborad)})
            
        server.stop()
```

### 主程式（main）
```python=
import Socket_Server
import Image_Analysis
import Data_Processing
import Image_Shading2_Dashborad

from multiprocessing import Queue, Process
import cv2
import os

class test(Process):
    def __init__(self, queue1, queue2):
        super(test, self).__init__()
        
        self.queue1 = queue1
        self.queue2 = queue2
        
    def convert_img(self, img):
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        return img
    
    def run(self):
        print("test: {}".format(os.getpid()))
        while 1:
            img = self.queue1.get(True)
            img = self.convert_img(img)
            self.queue2.put(img)
            
class get_local_img(Process):
    def __init__(self, queue1, queue2, width, height, fps):
        super(get_local_img, self).__init__()
        
        self.queue1 = queue1
        self.queue2 = queue2
        
        self.width = width
        self.height = height
        self.fps = fps
        
    def run(self):
        print("get_img_local: {}".format(os.getpid()))
        
        cap = cv2.VideoCapture(0 + cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        cap.set(cv2.CAP_PROP_FPS, self.fps)
        cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*"MJPG"))
        
        show_frame1 = None
        while 1:
            ret, frame = cap.read()
            if not ret:
                print("Can't receive frame (stream end?). Exiting ...")
                break
            
            self.queue1.put(frame)
            try:
                show_frame = self.queue2.get(True, timeout=1)
                show_frame1 = show_frame
            except:
                show_frame = show_frame1
                
            if show_frame is not None:
                cv2.imshow("Augmented Reality (Local Test)", show_frame)
                if cv2.waitKey(1) == ord("q"):
                    break
            
        cap.release()
        cv2.destroyAllWindows()
            
if __name__ == "__main__":  
    SS2IA = Queue()
    IA2IS = Queue()
    IS2SS = Queue()
    DP2IS = Queue()
    
    p1 = Socket_Server.Socket_Server(SS2IA, IS2SS, "127.0.0.1", 7000)
    p2 = Image_Analysis.Image_Analysis(SS2IA, IA2IS, IS2SS, "Camera_Calibration/Demo_Camera_parameter_20220518.npz")
    p3 = Image_Shading2_Dashborad.Image_Shading(IA2IS, IS2SS, DP2IS, 1280, 720, "OBJ_File/CNC_test6.obj", 1)
    p4 = Data_Processing.Data_Processing(DP2IS, "127.0.0.1", 4840)
    
    p1.start()
    p2.start()
    p3.start()
    p4.start()
    
    p1.join()
    p2.join()
    p3.join()
    p4.join()
```

## Reference
### 多程序
[python多进程和多线程看这一篇就够了](https://blog.csdn.net/Victor2code/article/details/109005171)
[【Python教學】淺談 Multi-processing & Multi-threading 使用方法](https://www.maxlist.xyz/2020/03/15/python-threading/)
[Python — 多線程](https://medium.com/jeasee%E9%9A%A8%E7%AD%86/python-%E5%A4%9A%E7%B7%9A%E7%A8%8B-eb36272e604b)
[【Python教學】淺談 Multi-processing pool 使用方法](https://www.maxlist.xyz/2020/03/20/multi-processing-pool/)
[python多進程基礎](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/701565/)
[多进程-廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/1016959663602400/1017628290184064)
[Python multiprocessing 模組進階說明與範例](https://myapollo.com.tw/zh-tw/more-about-python-multiprocessing/)
[Python程序間通訊 multiProcessing Queue佇列實現詳解](https://www.796t.com/article.php?id=10770)
[queue — A synchronized queue class — Python 3.10.4 documentation](https://docs.python.org/3/library/queue.html)
[python类内部实现多进程](https://blog.csdn.net/Damon_duanlei/article/details/88676632)
[一篇文章搞定Python多进程(全)](https://zhuanlan.zhihu.com/p/64702600)
[[Day33] python的super繼承](https://ithelp.ithome.com.tw/articles/10222948)

### 數據處理（Data Processing）
[[程式觀念] 大家都會使用plt畫圖，但是你真的知道plt / ax / fig是什麼嗎?怎麼用?](https://chwang12341.medium.com/%E7%A8%8B%E5%BC%8F%E8%A7%80%E5%BF%B5-%E5%A4%A7%E5%AE%B6%E9%83%BD%E6%9C%83%E4%BD%BF%E7%94%A8plt%E7%95%AB%E5%9C%96-%E4%BD%86%E6%98%AF%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%9F%A5%E9%81%93plt-ax-fig%E6%98%AF%E4%BB%80%E9%BA%BC%E5%97%8E-%E6%80%8E%E9%BA%BC%E7%94%A8-6f0bc6404f8f)

[Convert an image shown in python, into an OpenCV image.-Stack Overflow](https://stackoverflow.com/questions/42603161/convert-an-image-shown-in-python-into-an-opencv-image)

### 影像渲染（Image Shading）
[OpenGL 筆記 - Texture](http://blog.roy4801.tw/2020/07/09/opengl/opengl-note-4/)
[Day 12 [OpenGL] Textures](https://ithelp.ithome.com.tw/articles/10243700)
[第三课：矩阵](http://www.opengl-tutorial.org/cn/beginners-tutorials/tutorial-3-matrices/)
[Basic Transformations in OPENGL-GeeksforGeeks](https://www.geeksforgeeks.org/basic-transformations-opengl/)
[GLSL 详解（基础篇）](https://colin1994.github.io/2017/11/11/OpenGLES-Lesson04/)

### 主程式（main）
[[問題] Opencv 讀取高解析度Webcam時FPS很低-看板Python-批踢踢實業坊](https://www.ptt.cc/bbs/Python/M.1638980510.A.9A1.html)

### AR可視化介面
[C#的BackgroundWorker--啟動後臺執行緒](https://www.796t.com/content/1550455929.html)
[C# BackgroundWorker使用教程](https://www.itread01.com/article/1537410374.html)
[驅動一款淘寶購買的130萬像素的USB雙目攝像頭-記錄-台部落](https://www.twblogs.net/a/5ea5a8ac6052e135c9309a2c)
[【OpenCVSharp开启高清摄像头】](https://blog.csdn.net/weixin_44029053/article/details/124710457)